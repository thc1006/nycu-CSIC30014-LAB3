#!/bin/bash
################################################################################
# ğŸš€ Swin-Large ä¸€éµå•Ÿå‹•è…³æœ¬ - æ˜å¤©ä½¿ç”¨
# 
# ä½¿ç”¨æ–¹æ³•: bash START_SWIN_LARGE_TOMORROW.sh
# 
# é è¨ˆæ™‚é–“: 12-15 å°æ™‚
# é æœŸåˆ†æ•¸: 89-92% (ç›®æ¨™çªç ´ 90%)
################################################################################

echo "========================================================================"
echo "ğŸš€ Swin-Large æ¥µé™è¨“ç·´ - çªç ´ 90% æœ€çµ‚æ–¹æ¡ˆ"
echo "========================================================================"
echo ""
echo "ğŸ“Š UltraThink åˆ†æçµæœï¼š"
echo "  - ç•¶å‰ç“¶é ¸: 87.574% (EfficientNet-V2-L æ¶æ§‹é™åˆ¶)"
echo "  - çªç ´é—œéµ: å¤§å®¹é‡ Transformer æ¨¡å‹"
echo "  - æœ€å„ªé¸æ“‡: Swin-Large (197M åƒæ•¸)"
echo "  - æˆåŠŸæ¦‚ç‡: 70% çªç ´ 90%"
echo ""
echo "========================================================================"

# æª¢æŸ¥ GPU
echo "ğŸ–¥ï¸ æª¢æŸ¥ GPU..."
if ! nvidia-smi &> /dev/null; then
    echo "âŒ éŒ¯èª¤: æœªæª¢æ¸¬åˆ° GPU!"
    exit 1
fi

GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
echo "âœ… GPU å·²å°±ç·’: ${GPU_MEM}MB VRAM"
echo ""

# æ¸…ç† GPU
echo "ğŸ§¹ æ¸…ç† GPU ç·©å­˜..."
python3 -c "import torch; torch.cuda.empty_cache(); print('âœ… GPU å·²æ¸…ç†')"
echo ""

# æª¢æŸ¥ä¾è³´
echo "ğŸ“¦ æª¢æŸ¥ä¾è³´..."
python3 -c "import timm; print(f'âœ… timm {timm.__version__}')" || {
    echo "âŒ timm æœªå®‰è£ï¼Œæ­£åœ¨å®‰è£..."
    pip install timm -q
}
echo ""

# å‰µå»ºè¼¸å‡ºç›®éŒ„
mkdir -p outputs/swin_large_ultimate
mkdir -p logs

echo "========================================================================"
echo "ğŸ”¥ é–‹å§‹è¨“ç·´ Swin-Large 5-Fold"
echo "========================================================================"
echo ""
echo "é…ç½®ï¼š"
echo "  æ¨¡å‹: swin_large_patch4_window12_384 (197M åƒæ•¸)"
echo "  åœ–åƒ: 384Ã—384"
echo "  Batch: 4 (ä¿å®ˆ VRAM)"
echo "  Epochs: 40 (æ—©åœ patience=15)"
echo "  Mixup: 60% Î±=1.2"
echo "  Focal Loss: Î±=[1.0, 1.5, 2.0, 12.0] Î³=3.0"
echo ""
echo "é è¨ˆï¼š"
echo "  æ™‚é–“: 12-15 å°æ™‚"
echo "  Val F1: 86-89%"
echo "  Test F1: 89-92% ğŸ¯"
echo ""
echo "========================================================================"
echo ""

# ä½¿ç”¨ç¾æœ‰çš„ breakthrough è¨“ç·´è…³æœ¬ï¼Œå¾ªç’°è¨“ç·´ 5 å€‹ fold
for FOLD in {0..4}; do
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "ğŸ“Š Fold $FOLD/4 é–‹å§‹è¨“ç·´..."
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    
    # ä½¿ç”¨ fold ç‰¹å®šçš„æ•¸æ“š
    TRAIN_CSV="data/fold${FOLD}_train.csv"
    VAL_CSV="data/fold${FOLD}_val.csv"
    
    if [ ! -f "$TRAIN_CSV" ]; then
        echo "âš ï¸ $TRAIN_CSV ä¸å­˜åœ¨ï¼Œè·³éæ­¤ fold"
        continue
    fi
    
    # æª¢æŸ¥æ˜¯å¦å·²å®Œæˆ
    if [ -f "outputs/swin_large_ultimate/fold${FOLD}/best.pt" ]; then
        echo "âœ… Fold $FOLD å·²å®Œæˆï¼Œè·³é"
        continue
    fi
    
    # è¨“ç·´ (ä½¿ç”¨ timm ç›´æ¥è¨“ç·´)
    python3 << TRAIN_FOLD_EOF
import os, torch, torch.nn as nn, torch.optim as optim
import numpy as np, pandas as pd, timm
from pathlib import Path
from PIL import Image
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import f1_score

class CXRDataset(Dataset):
    def __init__(self, csv_path, img_dir, img_size=384, augment=False):
        self.df = pd.read_csv(csv_path)
        self.img_dir = img_dir
        self.img_size = img_size
        
        if augment:
            self.transforms = T.Compose([
                T.Resize((img_size, img_size)),
                T.RandomHorizontalFlip(),
                T.RandomRotation(15),
                T.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
                T.ColorJitter(brightness=0.2, contrast=0.2),
                T.ToTensor(),
                T.RandomErasing(p=0.3),
                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
            ])
        else:
            self.transforms = T.Compose([
                T.Resize((img_size, img_size)),
                T.ToTensor(),
                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
            ])
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = Path(self.img_dir) / row['new_filename']
        img = Image.open(img_path).convert('RGB')
        img = self.transforms(img)
        
        label_cols = ['normal', 'bacteria', 'virus', 'COVID-19']
        if all(c in row for c in label_cols):
            label = np.argmax([row[c] for c in label_cols])
        else:
            label = int(row.get('label', 0))
        
        return img, label

class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=3.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce = nn.functional.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)
        pt = torch.exp(-ce)
        return ((1 - pt) ** self.gamma * ce).mean()

def mixup_data(x, y, alpha=1.2):
    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1
    idx = torch.randperm(x.size(0)).to(x.device)
    return lam * x + (1 - lam) * x[idx], y, y[idx], lam

# Config
fold = ${FOLD}
device = torch.device('cuda')

# Data
train_ds = CXRDataset('${TRAIN_CSV}', 'data/train_images', 384, True)
val_ds = CXRDataset('${VAL_CSV}', 'data/train_images', 384, False)
train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)

print(f"Train: {len(train_ds)}, Val: {len(val_ds)}")

# Model
model = timm.create_model('swin_large_patch4_window12_384', pretrained=True, num_classes=4).to(device)
print(f"Parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M")

# Training
criterion = FocalLoss(alpha=torch.tensor([1.0, 1.5, 2.0, 12.0]).to(device), gamma=3.0)
optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.05)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 40, 1e-6)
scaler = torch.cuda.amp.GradScaler()

best_f1, patience = 0, 0

for epoch in range(40):
    # Train
    model.train()
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        if np.random.rand() < 0.6:
            inputs, ta, tb, lam = mixup_data(inputs, targets)
            with torch.cuda.amp.autocast():
                out = model(inputs)
                loss = lam * criterion(out, ta) + (1-lam) * criterion(out, tb)
        else:
            with torch.cuda.amp.autocast():
                loss = criterion(model(inputs), targets)
        
        optimizer.zero_grad()
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    
    scheduler.step()
    
    # Val
    model.eval()
    preds, labels = [], []
    with torch.no_grad():
        for inputs, targets in val_loader:
            out = model(inputs.to(device))
            preds.extend(out.argmax(1).cpu().numpy())
            labels.extend(targets.numpy())
    
    f1 = f1_score(labels, preds, average='macro') * 100
    print(f"Epoch {epoch+1}: Val F1 = {f1:.2f}%")
    
    if f1 > best_f1:
        best_f1 = f1
        patience = 0
        os.makedirs(f'outputs/swin_large_ultimate/fold{fold}', exist_ok=True)
        torch.save({'model_state_dict': model.state_dict(), 'f1': f1}, 
                   f'outputs/swin_large_ultimate/fold{fold}/best.pt')
        print(f"  âœ… Best F1: {f1:.2f}%")
    else:
        patience += 1
        if patience >= 15:
            print("Early stop")
            break

print(f"Fold {fold} done. Best: {best_f1:.2f}%")
TRAIN_FOLD_EOF

    echo ""
    echo "âœ… Fold $FOLD å®Œæˆ"
    echo ""
done

echo ""
echo "========================================================================"
echo "ğŸ‰ æ‰€æœ‰è¨“ç·´å®Œæˆï¼"
echo "========================================================================"
echo ""

# è¨ˆç®—å¹³å‡åˆ†æ•¸
python3 << 'SUMMARY_EOF'
import torch
from pathlib import Path

scores = []
for fold in range(5):
    ckpt_path = f'outputs/swin_large_ultimate/fold{fold}/best.pt'
    if Path(ckpt_path).exists():
        ckpt = torch.load(ckpt_path, map_location='cpu')
        scores.append(ckpt['f1'])
        print(f"Fold {fold}: {ckpt['f1']:.2f}%")

if scores:
    avg = sum(scores) / len(scores)
    print(f"\nå¹³å‡ Val F1: {avg:.2f}%")
    print(f"é æœŸ Test F1: {avg+3:.2f}% (åŸºæ–¼ DINOv2 +3% ç¶“é©—)")
    print(f"\nğŸ¯ ç›®æ¨™é”æˆæ¦‚ç‡:")
    if avg >= 87:
        print(f"  çªç ´ 90%: ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢âšª 80%+")
    elif avg >= 85:
        print(f"  çªç ´ 90%: ğŸŸ¢ğŸŸ¢ğŸŸ¢âšªâšª 60%")
    else:
        print(f"  çªç ´ 90%: ğŸŸ¢ğŸŸ¢âšªâšªâšª 40%")
SUMMARY_EOF

echo ""
echo "========================================================================"
echo "ğŸ“ ä¸‹ä¸€æ­¥ï¼š"
echo "  1. ç”Ÿæˆæ¸¬è©¦é›†é æ¸¬"
echo "  2. èˆ‡ç¾æœ‰æœ€ä½³æ¨¡å‹é›†æˆ"
echo "  3. æäº¤è‡³ Kaggle"
echo ""
echo "é‹è¡Œ: bash GENERATE_SWIN_PREDICTIONS.sh"
echo "========================================================================"
