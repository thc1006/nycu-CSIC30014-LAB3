{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Stage 1 Training on Google Colab A100\n",
    "\n",
    "This notebook trains the Stage 1 optimized model (ConvNeXt-Base + 512px) on Google Colab with A100 GPU.\n",
    "\n",
    "**Expected performance**: 85-87% Macro-F1 (up from 80.1% baseline)\n",
    "\n",
    "**Training time**: ~2 hours on A100 (vs 4-5 hours on RTX 3050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n",
    "\n",
    "âš ï¸ **Important**: Make sure you have selected **A100 GPU** in Runtime > Change runtime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU type\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repository\n",
    "!git clone https://github.com/thc1006/nycu-CSIC30014-LAB3.git\n",
    "%cd nycu-CSIC30014-LAB3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q --upgrade pip\n",
    "# PyTorch with CUDA 12.1 (compatible with Colab as of Oct 2025)\n",
    "pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Mount Google Drive and Setup Data\n",
    "\n",
    "**Before running this cell**, make sure you have uploaded your image directories to Google Drive:\n",
    "\n",
    "```\n",
    "MyDrive/chest-xray-data/\n",
    "  â”œâ”€â”€ train_images/\n",
    "  â”œâ”€â”€ val_images/\n",
    "  â””â”€â”€ test_images/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Update Config for Colab Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Update config paths for Colab\n",
    "config_path = 'configs/model_stage1.yaml'\n",
    "\n",
    "# Read base config\n",
    "with open('configs/base.yaml', 'r') as f:\n",
    "    base_config = yaml.safe_load(f)\n",
    "\n",
    "# Read stage1 config\n",
    "with open(config_path, 'r') as f:\n",
    "    stage1_config = yaml.safe_load(f)\n",
    "\n",
    "# Update paths for Colab + Google Drive\n",
    "base_config['data']['images_dir_train'] = '/content/drive/MyDrive/chest-xray-data/train_images'\n",
    "base_config['data']['images_dir_val'] = '/content/drive/MyDrive/chest-xray-data/val_images'\n",
    "base_config['data']['images_dir_test'] = '/content/drive/MyDrive/chest-xray-data/test_images'\n",
    "base_config['data']['train_csv'] = 'data/train_data.csv'\n",
    "base_config['data']['val_csv'] = 'data/val_data.csv'\n",
    "base_config['data']['test_csv'] = 'data/test_data.csv'\n",
    "base_config['out']['submission_path'] = 'submission_stage1_colab.csv'\n",
    "\n",
    "# Increase batch size for A100\n",
    "if 'train' not in stage1_config:\n",
    "    stage1_config['train'] = {}\n",
    "stage1_config['train']['batch_size'] = 24  # A100 can handle larger batches\n",
    "\n",
    "# Save updated base config\n",
    "with open('configs/base.yaml', 'w') as f:\n",
    "    yaml.dump(base_config, f)\n",
    "\n",
    "# Save updated stage1 config\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(stage1_config, f)\n",
    "\n",
    "print(\"âœ“ Config updated for Colab\")\n",
    "print(f\"  Train images: {base_config['data']['images_dir_train']}\")\n",
    "print(f\"  Batch size: {stage1_config['train']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Verify CUDA and Enable Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Enable TF32 for A100 (significant speedup)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"\\nâœ“ Optimizations enabled:\")\n",
    "print(f\"  TF32 matmul: {torch.backends.cuda.matmul.allow_tf32}\")\n",
    "print(f\"  TF32 cuDNN: {torch.backends.cudnn.allow_tf32}\")\n",
    "print(f\"  cuDNN benchmark: {torch.backends.cudnn.benchmark}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate test_data.csv (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/test_data.csv'):\n",
    "    print(\"Generating test_data.csv...\")\n",
    "    !python -m src.build_test_csv --config configs/model_stage1.yaml\n",
    "else:\n",
    "    print(\"âœ“ test_data.csv already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run Component Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test to verify everything works\n",
    "!python test_stage1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Start Training! ðŸš€\n",
    "\n",
    "This will take approximately **2 hours** on A100.\n",
    "\n",
    "You'll see output like:\n",
    "```\n",
    "[epoch 01] train acc=0.3500 f1=0.2800 | val acc=0.4500 f1=0.3500\n",
    "[epoch 10] train acc=0.8000 f1=0.7800 | val acc=0.7900 f1=0.7700\n",
    "[epoch 20] train acc=0.8800 f1=0.8700 | val acc=0.8500 f1=0.8400\n",
    "[epoch 30] train acc=0.9200 f1=0.9100 | val acc=0.8700 f1=0.8600\n",
    "[SWA final] val acc=0.8750 f1=0.8650\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.train_v2 --config configs/model_stage1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and generate confusion matrix\n",
    "!python -m src.eval --config configs/model_stage1.yaml --ckpt outputs/stage1_convnext512/best_swa.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Generate Predictions with TTA\n",
    "\n",
    "Test-Time Augmentation will give us an additional **+2-3% boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with Test-Time Augmentation\n",
    "!python -m src.tta_predict --config configs/model_stage1.yaml --ckpt outputs/stage1_convnext512/best_swa.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download submission file\n",
    "files.download('submission_stage1_colab.csv')\n",
    "\n",
    "# Optional: Download model checkpoint\n",
    "# files.download('outputs/stage1_convnext512/best_swa.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Training Complete!\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "- **Validation Macro-F1**: 0.86-0.87\n",
    "- **Expected Public Score**: 0.87-0.89 (with TTA)\n",
    "- **Improvement**: +7-9% from baseline (0.801)\n",
    "\n",
    "### Per-Class F1 Improvements:\n",
    "\n",
    "| Class | Baseline | Expected | Improvement |\n",
    "|-------|----------|----------|-------------|\n",
    "| Normal | 0.897 | 0.930-0.950 | +3-5% |\n",
    "| Bacteria | 0.762 | 0.840-0.870 | +8-11% |\n",
    "| **Virus** | 0.619 | 0.800-0.840 | **+18-22%** |\n",
    "| COVID-19 | 0.875 | 0.920-0.970 | +5-10% |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Submit to Kaggle** and check your Public Score\n",
    "2. **Stage 2**: Train ensemble of 3 models for 88-90%\n",
    "3. **Stage 3**: Multi-scale training for 90-93%\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Check the documentation:\n",
    "- `START_HERE.md` - Quick start guide\n",
    "- `RUN_STAGE1.md` - Detailed technical docs\n",
    "- `data/README.md` - Data setup instructions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
