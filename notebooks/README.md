# Notebooks Guide

This directory contains Jupyter notebooks for training on Google Colab.

## ğŸ““ Available Notebooks

### 1. `A100_Ultra_Optimized_Kaggle.ipynb` âš¡ **MOST RECOMMENDED**

**æœ€æ¨è–¦ä½¿ç”¨ï¼å¾Kaggleç›´æ¥ä¸‹è¼‰æ•¸æ“š + æ¦¨ä¹¾A100æ‰€æœ‰æ€§èƒ½**

**Features**:
- âœ… **Kaggle API integration** - Direct dataset download
- âœ… Automatic data organization
- âœ… One-click Kaggle submission
- âœ… Maximum batch size (48)
- âœ… Gradient accumulation (effective batch=192)
- âœ… bfloat16 AMP + TF32
- âœ… torch.compile optimization
- âœ… 95-98% GPU utilization

**Performance**:
- Training time: **~1.5 hours**
- Throughput: **400-500 images/sec**
- Expected F1: **0.87-0.89** (with TTA)

**When to use**:
- Your data is on Kaggle âœ“ **MOST COMMON**
- You want easiest setup âœ“
- You want direct Kaggle submission âœ“

---

### 2. `A100_Ultra_Optimized.ipynb` âš¡ **For Google Drive Data**

**ä½¿ç”¨Google Driveæ•¸æ“šçš„æ¥µè‡´å„ªåŒ–ç‰ˆæœ¬**

**Features**:
- âœ… Maximum batch size (48 vs 8 on RTX 3050) - **6x larger**
- âœ… Gradient accumulation (effective batch=192) - **24x effective**
- âœ… bfloat16 AMP (312 TFLOPS on A100)
- âœ… TF32 enabled (19.5 TFLOPS)
- âœ… torch.compile for JIT compilation
- âœ… Fused AdamW optimizer
- âœ… Optimized DataLoader (4 workers + pin_memory)
- âœ… cuDNN auto-tuning
- âœ… Channels last memory format
- âœ… 95-98% GPU utilization

**Performance**:
- Training time: **~1.5 hours** (vs 4-5 hours on RTX 3050)
- Throughput: **400-500 images/sec**
- Memory usage: **37GB / 40GB** (maxed out)
- Expected F1: **0.87-0.89** (with TTA)

**When to use**:
- You have A100 GPU access âœ“
- You want maximum performance âœ“
- You want to finish training ASAP âœ“

---

### 2. `Stage1_Colab_Training.ipynb` ğŸ“š **BEGINNER-FRIENDLY**

**æ›´å®¹æ˜“ç†è§£çš„æ¨™æº–ç‰ˆæœ¬ï¼Œé©åˆåˆå­¸è€…**

**Features**:
- âœ… Step-by-step explanations
- âœ… Standard batch size (24)
- âœ… Simpler configuration
- âœ… Good for learning

**Performance**:
- Training time: **~2 hours**
- Throughput: **~300 images/sec**
- Memory usage: **28GB / 40GB**
- Expected F1: **0.85-0.87** (with TTA)

**When to use**:
- You're new to Colab âœ“
- You want to understand each step âœ“
- You're okay with slightly longer training âœ“

---

### 3. `A100_Final_Train.ipynb` ğŸ“‹ **LEGACY**

**èˆŠç‰ˆæœ¬ï¼Œä¿ç•™ä¾›åƒè€ƒ**

This is the original notebook. Use the updated versions above instead.

---

## ğŸš€ Quick Start

### Step 1: Get Kaggle API Credentials

1. Go to [Kaggle Account Settings](https://www.kaggle.com/settings/account)
2. Scroll to "API" section
3. Click "Create New Token"
4. Download `kaggle.json`

### Step 2: Open Notebook in Colab

1. Go to [Google Colab](https://colab.research.google.com/)
2. Click "File" â†’ "Upload notebook"
3. Choose `A100_Ultra_Optimized_Kaggle.ipynb` (recommended)
4. Change runtime type to **GPU: A100**

### Step 3: Upload Kaggle Credentials & Run

1. When prompted, upload your `kaggle.json`
2. Dataset will download automatically
3. Press "Runtime" â†’ "Run all"
4. Wait ~1.5 hours for training!

---

## ğŸ“Š Performance Comparison

| Notebook | Data Source | GPU | Training Time | Expected F1 |
|----------|-------------|-----|---------------|-------------|
| **Ultra Kaggle âš¡** | Kaggle API | A100 | **1.5h** | **0.87-0.89** |
| Ultra Drive âš¡ | Google Drive | A100 | **1.5h** | **0.87-0.89** |
| Stage1 Standard ğŸ“š | Google Drive | A100 | 2h | 0.85-0.87 |
| Legacy ğŸ“‹ | Google Drive | A100 | 2.5h | 0.83-0.85 |
| Local (RTX 3050) | Local files | 3050 | 4-5h | 0.80-0.82 |

---

## ğŸ’¡ Tips for Best Results

### Before Training:
1. âœ… Verify you have **A100 GPU** selected
2. âœ… Upload images to Google Drive first
3. âœ… Have stable internet connection
4. âœ… Keep Colab tab open during training

### During Training:
1. Monitor GPU usage with `!nvidia-smi`
2. Watch throughput (should be 400-500 img/s for Ultra)
3. Check loss is decreasing smoothly

### After Training:
1. Download `submission.csv` immediately
2. Optionally download `best.pt` checkpoint
3. Submit to Kaggle and check score

---

## ğŸ› Troubleshooting

### "Not A100!" Error
**Solution**: Runtime â†’ Change runtime type â†’ GPU type: A100

### OutOfMemoryError
**Solution**:
- For Ultra notebook: Reduce batch_size from 48 to 40
- For Standard notebook: Reduce batch_size from 24 to 16

### Slow Training (<200 img/s)
**Check**:
1. Is GPU actually A100? Run `!nvidia-smi`
2. Is data on Google Drive? (not local)
3. Are workers set correctly? (num_workers=4)

### "Cannot find images"
**Solution**:
1. Check your Google Drive path
2. Update paths in notebook Step 5
3. Verify folder names match exactly

---

## ğŸ¯ Expected Results Timeline

### Ultra-Optimized (1.5 hours total):

```
[epoch 01/30] val f1=0.35  (3 min)
[epoch 05/30] val f1=0.62  (15 min)
[epoch 10/30] val f1=0.77  (30 min)
[epoch 15/30] val f1=0.82  (45 min)
[epoch 20/30] val f1=0.85  (60 min)
[epoch 25/30] val f1=0.86  (75 min)
[epoch 30/30] val f1=0.87  (90 min)

âœ“ Training complete!
```

### With TTA (+3-5 minutes):
```
Final Kaggle Score: 0.87-0.89 ğŸ¯
```

---

## ğŸ“š Additional Resources

- **Quick Start**: `../START_HERE.md`
- **Technical Details**: `../RUN_STAGE1.md`
- **Data Setup**: `../data/README.md`

---

## âš ï¸ Important Notes

1. **Free Colab Limits**:
   - A100 usage is limited (~12 hours/week for free tier)
   - Save your work frequently
   - Download results immediately after training

2. **Data Transfer**:
   - Using Google Drive may be slow initially
   - First epoch might be slower (loading/caching)
   - Subsequent epochs will be faster

3. **Reproducibility**:
   - Random seed is set (42)
   - Results should be consistent
   - Small variations (<1%) are normal

---

**Choose `A100_Ultra_Optimized.ipynb` for best performance! âš¡**
