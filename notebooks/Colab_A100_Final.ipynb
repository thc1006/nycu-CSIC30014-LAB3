{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Chest X-Ray Classification - Optimized for 80%+ Score\n",
    "\n",
    "**Target Score: 80-82% (Public Leaderboard)**\n",
    "\n",
    "## üìã Strategy:\n",
    "\n",
    "This notebook reproduces the **80.122% baseline** configuration that actually works!\n",
    "\n",
    "### Why This Approach?\n",
    "\n",
    "After extensive experiments (Exp1-5), we found:\n",
    "- ‚ùå Complex models (ConvNeXt-Base, 512px) ‚Üí **Lower scores** (76-72%)\n",
    "- ‚úÖ **Simple config (ResNet18, 224px) ‚Üí 80.122%** ‚ú®\n",
    "\n",
    "### Key Success Factors:\n",
    "\n",
    "1. ‚úÖ **ResNet18** (not ConvNeXt) - Simple but effective\n",
    "2. ‚úÖ **224px** (not 512px) - Optimal resolution\n",
    "3. ‚úÖ **Weighted Sampler** - Handles COVID-19 (only 1% samples)\n",
    "4. ‚úÖ **Label Smoothing 0.05** - Prevents overfitting\n",
    "5. ‚úÖ **TTA** - Test-Time Augmentation for +1-2% boost\n",
    "\n",
    "## ‚è±Ô∏è Time Required:\n",
    "\n",
    "- **Setup**: 5-10 minutes\n",
    "- **Training**: 15-20 minutes (A100) or 40-60 minutes (T4)\n",
    "- **TTA Inference**: 3-5 minutes\n",
    "- **Total**: ~30 minutes on A100\n",
    "\n",
    "## üéØ Expected Performance:\n",
    "\n",
    "| Method | Val F1 | Public Score | Time (A100) |\n",
    "|--------|--------|--------------|-------------|\n",
    "| Baseline | 0.80-0.82 | 80-81% | 15 min |\n",
    "| **Baseline + TTA** | **0.81-0.83** | **81-82%** | **20 min** |\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Before You Start:\n",
    "\n",
    "### 1. Change Runtime Type:\n",
    "- Click: `Runtime` ‚Üí `Change runtime type`\n",
    "- Hardware accelerator: **GPU**\n",
    "- GPU type: **A100** (fastest) or T4 (slower but works)\n",
    "\n",
    "### 2. Get Kaggle API Key:\n",
    "- Go to: https://www.kaggle.com/settings\n",
    "- Scroll to \"API\" section\n",
    "- Click \"Create New API Token\"\n",
    "- Download `kaggle.json`\n",
    "\n",
    "### 3. Join Competition:\n",
    "- Visit: https://www.kaggle.com/competitions/cxr-multi-label-classification\n",
    "- Click \"Join Competition\" and accept rules\n",
    "\n",
    "### 4. Run All Cells:\n",
    "- Just click: `Runtime` ‚Üí `Run all`\n",
    "- Upload `kaggle.json` when prompted\n",
    "- Wait ~30 minutes for training + TTA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Verify GPU\n",
    "\n",
    "‚ö†Ô∏è **CRITICAL**: You MUST have GPU enabled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"\\n[OK] GPU: {gpu_name}\")\n",
    "    print(f\"[OK] Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"[OK] CUDA: {torch.version.cuda}\")\n",
    "    print(f\"[OK] PyTorch: {torch.__version__}\")\n",
    "    \n",
    "    if \"A100\" in gpu_name:\n",
    "        print(\"\\nüöÄ EXCELLENT: A100 GPU detected!\")\n",
    "        print(\"   Training will take ~15-20 minutes\")\n",
    "    elif \"T4\" in gpu_name:\n",
    "        print(\"\\n‚ö° GOOD: T4 GPU detected!\")\n",
    "        print(\"   Training will take ~40-60 minutes\")\n",
    "    else:\n",
    "        print(f\"\\n‚ÑπÔ∏è  Detected: {gpu_name}\")\n",
    "    \n",
    "    # Enable optimizations\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print(f\"\\n[OK] TF32 enabled: {torch.backends.cuda.matmul.allow_tf32}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO GPU DETECTED!\")\n",
    "    print(\"\\n‚ö†Ô∏è  Please enable GPU:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    raise Exception(\"GPU required for training\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository\n",
    "\n",
    "Download the training code and pre-split data from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport shutil\n\nprint(\"=\" * 60)\nprint(\"CLONE REPOSITORY\")\nprint(\"=\" * 60)\n\nREPO_URL = \"https://github.com/thc1006/nycu-CSIC30014-LAB3.git\"\nPROJECT_DIR = \"nycu-CSIC30014-LAB3\"\n\n# IMPORTANT: Always start from /content to avoid nested directories\n%cd /content\n\nprint(f\"\\nCurrent directory: {os.getcwd()}\")\n\n# Remove if exists (to get latest version)\nif os.path.exists(PROJECT_DIR):\n    print(f\"Removing existing {PROJECT_DIR}...\")\n    shutil.rmtree(PROJECT_DIR)\n\n# Clone repository\nprint(f\"\\nCloning from GitHub...\")\n!git clone {REPO_URL}\n\n# Change to project directory using magic command\n%cd {PROJECT_DIR}\n\nprint(f\"\\n[OK] Working directory: {os.getcwd()}\")\n\n# Verify we are in the correct directory\nif not os.path.exists(\"src\") or not os.path.exists(\"configs\"):\n    print(\"\\n[ERROR] Wrong directory! Missing src/ or configs/\")\n    print(f\"Current dir contents: {os.listdir('.')}\")\n    raise Exception(\"Directory structure incorrect - check git clone\")\n\n# Verify no nested directories (should be /content/PROJECT_DIR, not /content/PROJECT_DIR/PROJECT_DIR)\ncwd = os.getcwd()\nif cwd.count(PROJECT_DIR) > 1:\n    print(f\"\\n[ERROR] Nested directory detected: {cwd}\")\n    print(\"Expected: /content/nycu-CSIC30014-LAB3\")\n    print(f\"Got: {cwd}\")\n    raise Exception(\"Nested directory structure - please restart runtime and re-run\")\n\n# Show structure\nprint(\"\\n[OK] Project structure:\")\n!ls -lh | head -15\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"INSTALL DEPENDENCIES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThis will take 1-2 minutes...\\n\")\n",
    "\n",
    "# Install PyTorch with CUDA 12.1\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q numpy pandas scikit-learn matplotlib tqdm pyyaml opencv-python seaborn albumentations\n",
    "\n",
    "# Install Kaggle API\n",
    "!pip install -q kaggle\n",
    "\n",
    "print(\"\\n[OK] Installation complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Kaggle API\n",
    "\n",
    "Upload your `kaggle.json` file to authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport subprocess\nfrom google.colab import files as colab_files\nfrom pathlib import Path\n\nprint(\"=\" * 60)\nprint(\"KAGGLE API SETUP\")\nprint(\"=\" * 60)\nprint(\"\\nPlease upload your kaggle.json file:\")\nprint(\"(Click 'Choose Files' button below)\\n\")\n\nuploaded = colab_files.upload()\n\nif 'kaggle.json' in uploaded:\n    print(\"\\n[OK] kaggle.json uploaded successfully!\")\n    \n    # Setup Kaggle credentials\n    kaggle_dir = Path.home() / '.kaggle'\n    kaggle_dir.mkdir(exist_ok=True)\n    \n    kaggle_json_path = kaggle_dir / 'kaggle.json'\n    with open(kaggle_json_path, 'wb') as f:\n        f.write(uploaded['kaggle.json'])\n    \n    # Set permissions\n    os.chmod(kaggle_json_path, 0o600)\n    \n    print(f\"   Saved to: {kaggle_json_path}\")\n    print(f\"   Permissions: 600\\n\")\n    \n    # Verify authentication\n    print(\"Verifying authentication...\")\n    result = subprocess.run(\n        ['kaggle', 'competitions', 'list', '--page', '1'],\n        capture_output=True,\n        text=True\n    )\n    \n    if result.returncode == 0:\n        print(\"[OK] Kaggle API authenticated!\\n\")\n    else:\n        print(\"[FAIL] Authentication failed!\")\n        print(f\"Error: {result.stderr}\")\nelse:\n    print(\"\\n[FAIL] kaggle.json not uploaded!\")\n    raise Exception(\"Please upload kaggle.json\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download Competition Dataset\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT**: You MUST join the competition first!\n",
    "- Visit: https://www.kaggle.com/competitions/cxr-multi-label-classification\n",
    "- Click \"Join Competition\" and accept rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import zipfile\nimport subprocess\nimport shutil\nfrom tqdm.auto import tqdm\n\nprint(\"=\" * 60)\nprint(\"DOWNLOAD COMPETITION DATASET\")\nprint(\"=\" * 60)\n\nCOMPETITION_NAME = \"cxr-multi-label-classification\"\n\nprint(f\"\\nCompetition: {COMPETITION_NAME}\")\nprint(\"\\nIMPORTANT: Make sure you've:\")\nprint(\"  1. Visited https://www.kaggle.com/competitions/cxr-multi-label-classification\")\nprint(\"  2. Clicked 'Join Competition'\")\nprint(\"  3. Accepted the rules\")\nprint(\"\\nDownloading (this may take 2-5 minutes)...\\n\")\n\n# Download from competition\nresult = subprocess.run(\n    ['kaggle', 'competitions', 'download', '-c', COMPETITION_NAME],\n    capture_output=True,\n    text=True\n)\n\nif result.returncode != 0:\n    if \"403\" in result.stderr or \"Forbidden\" in result.stderr:\n        print(\"[FAIL] 403 Forbidden Error!\")\n        print(\"\\nYou haven't accepted the competition rules yet.\")\n        print(f\"\\nPlease:\")\n        print(f\"  1. Visit: https://www.kaggle.com/competitions/{COMPETITION_NAME}\")\n        print(f\"  2. Click 'Join Competition'\")\n        print(f\"  3. Accept the rules\")\n        print(f\"  4. Re-run this cell\")\n        raise Exception(\"Need to join competition first\")\n    else:\n        print(f\"[FAIL] Download failed: {result.stderr}\")\n        raise Exception(\"Competition download failed\")\n\nprint(\"[OK] Competition data downloaded!\")\n\n# Extract all zip files\nprint(\"\\nExtracting files...\")\nzip_files = [f for f in os.listdir('.') if f.endswith('.zip')]\n\nif len(zip_files) == 0:\n    print(\"[FAIL] No zip files found!\")\nelse:\n    for zip_file in zip_files:\n        print(f\"\\n  Processing: {zip_file}\")\n        \n        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n            file_list = zip_ref.namelist()\n            \n            for file in tqdm(file_list, desc=\"  Extracting\", leave=False):\n                zip_ref.extract(file, '.')\n        \n        os.remove(zip_file)\n        print(f\"  [OK] Extracted and removed {zip_file}\")\n\n# Organize data structure according to CSV splits\nprint(\"\\n\" + \"=\" * 60)\nprint(\"ORGANIZING DATA STRUCTURE\")\nprint(\"=\" * 60)\n\nimport pandas as pd\n\n# Step 1: Collect all images from wherever they are\nprint(\"\\nStep 1: Collecting all images...\")\n\nall_images = {}  # filename -> current_path\n\n# Search in common locations\nsearch_dirs = ['.', 'train_images', 'val_images', 'test_images']\n\nfor search_dir in search_dirs:\n    if not os.path.exists(search_dir):\n        continue\n    \n    for fname in os.listdir(search_dir):\n        if fname.endswith(('.jpg', '.jpeg', '.png')):\n            # Store the path where we found this image\n            if fname not in all_images:  # First occurrence wins\n                all_images[fname] = os.path.join(search_dir, fname)\n\nprint(f\"[OK] Found {len(all_images)} total images\")\n\n# Step 2: Ensure data directory exists and has CSVs\nif not os.path.exists('data'):\n    os.makedirs('data', exist_ok=True)\n    print(\"[INFO] Created data/ directory\")\n\n# Move any CSV files from root to data/\nfor fname in ['train_data.csv', 'val_data.csv', 'test_data.csv']:\n    if os.path.exists(fname) and not os.path.exists(f'data/{fname}'):\n        shutil.move(fname, f'data/{fname}')\n        print(f\"[OK] Moved {fname} to data/\")\n\n# Step 3: Reorganize images according to CSV splits\nsplits = {\n    'train': ('data/train_data.csv', 'train_images'),\n    'val': ('data/val_data.csv', 'val_images'),\n    'test': ('data/test_data.csv', 'test_images')\n}\n\nfor split_name, (csv_path, target_dir) in splits.items():\n    if not os.path.exists(csv_path):\n        print(f\"[SKIP] {csv_path} not found\")\n        continue\n    \n    # Read CSV to get required files\n    df = pd.read_csv(csv_path)\n    needed_files = set(df['new_filename'].values)\n    \n    print(f\"\\n{split_name.upper()} split: {len(needed_files)} images required\")\n    \n    # Create target directory\n    os.makedirs(target_dir, exist_ok=True)\n    \n    # Move/copy images to correct location\n    moved = 0\n    missing = []\n    \n    for fname in tqdm(needed_files, desc=f\"  Organizing {split_name}\", leave=False):\n        target_path = os.path.join(target_dir, fname)\n        \n        # Skip if already in correct location\n        if os.path.exists(target_path):\n            continue\n        \n        # Find and move from source\n        if fname in all_images:\n            source_path = all_images[fname]\n            \n            # Only move if different location\n            if os.path.abspath(source_path) != os.path.abspath(target_path):\n                shutil.move(source_path, target_path)\n                moved += 1\n                # Update registry\n                all_images[fname] = target_path\n        else:\n            missing.append(fname)\n    \n    # Clean up: remove extra files not in CSV\n    existing_files = [f for f in os.listdir(target_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n    extra_files = set(existing_files) - needed_files\n    \n    if extra_files:\n        print(f\"  Removing {len(extra_files)} extra files from {target_dir}/\")\n        for fname in extra_files:\n            os.remove(os.path.join(target_dir, fname))\n    \n    # Verify final count\n    final_count = len([f for f in os.listdir(target_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n    expected_count = len(needed_files)\n    \n    if moved > 0:\n        print(f\"  [OK] Moved {moved} images\")\n    print(f\"  [OK] {target_dir}: {final_count}/{expected_count} images\")\n    \n    if missing:\n        print(f\"  [WARNING] {len(missing)} images missing\")\n        for fname in missing[:3]:\n            print(f\"    - {fname}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DATA ORGANIZATION COMPLETE\")\nprint(\"=\" * 60)\n\n# Final summary\nprint(\"\\nFinal verification:\")\ntotal = 0\nfor split_name, (csv_path, target_dir) in splits.items():\n    if os.path.exists(target_dir):\n        count = len([f for f in os.listdir(target_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n        print(f\"  {target_dir}: {count} images\")\n        total += count\n\nprint(f\"  TOTAL: {total} images organized\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data\n",
    "\n",
    "Check that we have all required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\nprint(\"=\" * 60)\nprint(\"VERIFY DATA\")\nprint(\"=\" * 60)\n\n# Check directories and CSVs\nexpected_dirs = ['train_images', 'val_images', 'test_images']\nexpected_csvs = ['data/train_data.csv', 'data/val_data.csv', 'data/test_data.csv']\n\nall_good = True\n\nprint(\"\\nImage directories:\")\nfor dir_name in expected_dirs:\n    if os.path.exists(dir_name):\n        count = len([f for f in os.listdir(dir_name) if f.endswith(('.jpeg', '.jpg', '.png'))])\n        print(f\"  [OK] {dir_name}/ ({count} images)\")\n    else:\n        print(f\"  [FAIL] {dir_name}/ NOT FOUND\")\n        all_good = False\n\nprint(\"\\nCSV files:\")\nfor csv_file in expected_csvs:\n    if os.path.exists(csv_file):\n        df = pd.read_csv(csv_file)\n        print(f\"  [OK] {csv_file} ({len(df)} samples)\")\n        \n        # Show class distribution\n        if 'train' in csv_file or 'val' in csv_file:\n            label_cols = ['normal', 'bacteria', 'virus', 'COVID-19']\n            if all(col in df.columns for col in label_cols):\n                normal_count = int(df['normal'].sum())\n                bacteria_count = int(df['bacteria'].sum())\n                virus_count = int(df['virus'].sum())\n                covid_count = int(df['COVID-19'].sum())\n                print(f\"       Normal={normal_count}, Bacteria={bacteria_count}, Virus={virus_count}, COVID-19={covid_count}\")\n    else:\n        print(f\"  [FAIL] {csv_file} NOT FOUND\")\n        all_good = False\n\nif all_good:\n    print(\"\\n\" + \"=\" * 60)\n    print(\"[OK] ALL DATA VERIFIED!\")\n    print(\"=\" * 60)\nelse:\n    print(\"\\n[FAIL] Some files missing!\")\n    raise Exception(\"Data verification failed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: üî• Train Baseline Model (80.122% Config)\n",
    "\n",
    "### Configuration:\n",
    "- Model: **ResNet18** (not ConvNeXt!)\n",
    "- Image size: **224px** (not 512px!)\n",
    "- Batch size: 32 (A100) or 16 (T4)\n",
    "- Epochs: 12\n",
    "- Loss: CrossEntropy + **Label Smoothing 0.05**\n",
    "- **Weighted Sampler**: True (critical for COVID-19)\n",
    "- AMP: bfloat16\n",
    "\n",
    "### Expected:\n",
    "- Training time: 15-20 min (A100)\n",
    "- Val F1: 0.80-0.82\n",
    "- GPU utilization: 60-80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify we are in correct directory\nimport os\nimport torch\n\nprint(\"=\" * 60)\nprint(\"PRE-TRAINING VALIDATION\")\nprint(\"=\" * 60)\nprint(f\"\\nWorking directory: {os.getcwd()}\")\n\n# Check critical paths exist\ncritical_paths = [\n    \"src/train_v2.py\",\n    \"configs/colab_baseline.yaml\",\n    \"train_images\",\n    \"val_images\",\n    \"data/train_data.csv\",\n    \"data/val_data.csv\"\n]\n\nall_ok = True\nfor path in critical_paths:\n    if os.path.exists(path):\n        print(f\"[OK] {path}\")\n    else:\n        print(f\"[ERROR] {path} NOT FOUND!\")\n        all_ok = False\n\nif not all_ok:\n    print(\"\\n[FAIL] Critical files missing!\")\n    print(f\"Current directory: {os.getcwd()}\")\n    print(f\"Contents: {os.listdir('.')}\")\n    raise Exception(\"Missing required files. Check working directory.\")\n\nprint(\"\\n[OK] All critical paths exist!\")\n\n# Auto-adjust batch size for T4 GPU\nprint(\"\\n\" + \"=\" * 60)\nprint(\"GPU-SPECIFIC CONFIGURATION\")\nprint(\"=\" * 60)\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    print(f\"GPU: {gpu_name}\")\n    \n    if \"T4\" in gpu_name:\n        print(\"\\n[INFO] T4 GPU detected - adjusting batch size to 16\")\n        \n        # Read config\n        with open('configs/colab_baseline.yaml', 'r') as f:\n            config_content = f.read()\n        \n        # Replace batch size\n        if 'batch_size: 32' in config_content:\n            config_content = config_content.replace('batch_size: 32', 'batch_size: 16')\n            \n            # Write back\n            with open('configs/colab_baseline.yaml', 'w') as f:\n                f.write(config_content)\n            \n            print(\"[OK] Batch size adjusted: 32 ‚Üí 16 for T4\")\n        else:\n            print(\"[INFO] Batch size already configured\")\n    else:\n        print(f\"[OK] Using default batch size (32) for {gpu_name}\")\n\n# Set PYTHONPATH\nos.environ['PYTHONPATH'] = os.getcwd()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TRAINING BASELINE MODEL (80.122% CONFIG)\")\nprint(\"=\" * 60)\nprint(f\"\\nConfig: configs/colab_baseline.yaml\")\nprint(f\"Model: ResNet18 @ 224px\")\nprint(f\"Epochs: 12\")\nprint(f\"Weighted Sampler: True\")\nprint(f\"Label Smoothing: 0.05\")\nprint(f\"\\nTraining time: ~15-20 minutes (A100) or 40-60 minutes (T4)\")\nprint(f\"\\nYou can monitor GPU: Runtime ‚Üí Manage sessions\")\nprint(\"=\" * 60)\nprint()\n\n# Train using the Colab baseline config (uses relative paths)\n!python -m src.train_v2 --config configs/colab_baseline.yaml\n\nprint()\nprint(\"=\" * 60)\nprint(\"TRAINING COMPLETE!\")\nprint(\"=\" * 60)\nprint(f\"\\nModel saved to: outputs/colab_baseline/best.pt\")\nprint(f\"\\nExpected Val F1: 0.80-0.82\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\nprint(\"=\" * 60)\nprint(\"EVALUATING TRAINED MODEL\")\nprint(\"=\" * 60)\nprint()\n\nmodel_path = 'outputs/colab_baseline/best.pt'\n\nif not os.path.exists(model_path):\n    print(f\"[FAIL] Model not found: {model_path}\")\n    print(\"   Please run Step 6 (Training) first.\")\nelse:\n    # Verify checkpoint is valid\n    try:\n        print(f\"[OK] Model found: {model_path}\")\n        print(\"Verifying checkpoint...\")\n        \n        test_load = torch.load(model_path, map_location='cpu')\n        \n        if 'model' not in test_load:\n            print(f\"[ERROR] Invalid checkpoint: missing 'model' key\")\n            print(f\"Available keys: {list(test_load.keys())}\")\n            raise Exception(\"Corrupted checkpoint\")\n        \n        print(f\"[OK] Checkpoint valid (keys: {list(test_load.keys())})\\n\")\n        del test_load\n        \n        !python -m src.eval --config configs/colab_baseline.yaml --ckpt {model_path}\n        \n    except Exception as e:\n        print(f\"[ERROR] Cannot load checkpoint: {e}\")\n        raise\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Generate Standard Predictions\n",
    "\n",
    "First, let's generate standard predictions (without TTA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\nprint(\"=\" * 60)\nprint(\"GENERATING STANDARD PREDICTIONS\")\nprint(\"=\" * 60)\nprint()\n\nmodel_path = 'outputs/colab_baseline/best.pt'\n\nif not os.path.exists(model_path):\n    print(f\"[FAIL] Model not found: {model_path}\")\nelse:\n    # Verify checkpoint is valid\n    try:\n        print(f\"[OK] Model found: {model_path}\")\n        print(\"Verifying checkpoint...\")\n        \n        test_load = torch.load(model_path, map_location='cpu')\n        \n        if 'model' not in test_load:\n            print(f\"[ERROR] Invalid checkpoint: missing 'model' key\")\n            raise Exception(\"Corrupted checkpoint\")\n        \n        print(f\"[OK] Checkpoint valid\\n\")\n        del test_load\n        \n        !python -m src.predict --config configs/colab_baseline.yaml --ckpt {model_path}\n        \n        print(\"\\n[OK] Predictions generated!\")\n        print(\"   Output: data/submission.csv\")\n        \n    except Exception as e:\n        print(f\"[ERROR] Cannot load checkpoint: {e}\")\n        raise\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate TTA Predictions (Recommended)\n",
    "\n",
    "Test-Time Augmentation for +0.5-1.5% improvement.\n",
    "\n",
    "### TTA Transforms:\n",
    "1. Original image\n",
    "2. Horizontal flip\n",
    "3. Vertical flip\n",
    "4. Rotate 90¬∞\n",
    "5. Rotate 180¬∞\n",
    "6. Rotate 270¬∞\n",
    "\n",
    "Average all 6 predictions for robust results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\nprint(\"=\" * 60)\nprint(\"GENERATING TTA PREDICTIONS\")\nprint(\"=\" * 60)\nprint()\nprint(\"Test-Time Augmentation:\")\nprint(\"  - 6 transformations (original, flips, rotations)\")\nprint(\"  - Averages predictions for robustness\")\nprint(\"  - Expected: +0.5-1.5% F1 boost\")\nprint()\n\nmodel_path = 'outputs/colab_baseline/best.pt'\n\nif not os.path.exists(model_path):\n    print(f\"[FAIL] Model not found: {model_path}\")\nelse:\n    # Verify checkpoint is valid\n    try:\n        print(f\"[OK] Model found: {model_path}\")\n        print(\"Verifying checkpoint...\")\n        \n        test_load = torch.load(model_path, map_location='cpu')\n        \n        if 'model' not in test_load:\n            print(f\"[ERROR] Invalid checkpoint: missing 'model' key\")\n            raise Exception(\"Corrupted checkpoint\")\n        \n        print(f\"[OK] Checkpoint valid\\n\")\n        del test_load\n        \n        !python -m src.tta_predict --config configs/colab_baseline.yaml --ckpt {model_path}\n        \n        print(\"\\n[OK] TTA Predictions generated!\")\n        print(\"   Output: submission_tta.csv\")\n        \n    except Exception as e:\n        print(f\"[ERROR] Cannot load checkpoint: {e}\")\n        raise\n\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nfrom google.colab import files as colab_files\n\nprint(\"=\" * 60)\nprint(\"DOWNLOAD SUBMISSION FILES\")\nprint(\"=\" * 60)\nprint()\n\n# Check both submission files\nstandard_file = 'data/submission.csv'\ntta_file = 'submission_tta.csv'\n\nfiles_to_download = []\n\nif os.path.exists(standard_file):\n    df = pd.read_csv(standard_file)\n    print(f\"[OK] {standard_file} ({len(df)} samples)\")\n    files_to_download.append(standard_file)\n    \n    # Show distribution\n    print(\"\\nStandard prediction distribution:\")\n    pred_counts = df[['normal', 'bacteria', 'virus', 'COVID-19']].sum()\n    for cls, count in pred_counts.items():\n        pct = count / len(df) * 100\n        print(f\"  {cls:12s}: {int(count):4d} ({pct:5.2f}%)\")\n\nif os.path.exists(tta_file):\n    df = pd.read_csv(tta_file)\n    print(f\"\\n[OK] {tta_file} ({len(df)} samples)\")\n    files_to_download.append(tta_file)\n    \n    # Show distribution\n    print(\"\\nTTA prediction distribution:\")\n    pred_counts = df[['normal', 'bacteria', 'virus', 'COVID-19']].sum()\n    for cls, count in pred_counts.items():\n        pct = count / len(df) * 100\n        print(f\"  {cls:12s}: {int(count):4d} ({pct:5.2f}%)\")\n\nif files_to_download:\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Downloading files...\")\n    print(\"=\" * 60)\n    \n    for file in files_to_download:\n        print(f\"\\nDownloading: {file}\")\n        colab_files.download(file)\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"DOWNLOAD COMPLETE!\")\n    print(\"=\" * 60)\n    print(\"\\nüìä EXPECTED KAGGLE SCORES:\")\n    print(\"   - Standard: 80-81%\")\n    print(\"   - TTA (recommended): 81-82%\")\n    print(\"\\nüìù NEXT STEPS:\")\n    print(\"   1. Go to Kaggle competition page\")\n    print(\"   2. Click 'Submit Predictions'\")\n    print(\"   3. Upload submission_tta.csv (recommended)\")\n    print(\"   4. Check your score on the leaderboard!\")\n    print(\"\\n\" + \"=\" * 60)\nelse:\n    print(\"\\n[FAIL] No submission files found!\")\n    print(\"Please run Steps 8 and 9 first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Training Complete!\n",
    "\n",
    "### Performance Summary:\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Model** | ResNet18 (11M params) |\n",
    "| **Image Size** | 224√ó224 |\n",
    "| **Training Time** | ~15-20 minutes (A100) |\n",
    "| **Expected Val F1** | 0.80-0.82 |\n",
    "| **Expected Public Score** | **80-82%** |\n",
    "\n",
    "### Why This Works:\n",
    "\n",
    "1. ‚úÖ **Simple is Better** - ResNet18 > Complex models for this dataset\n",
    "2. ‚úÖ **Weighted Sampler** - Handles COVID-19 (only 1% samples)\n",
    "3. ‚úÖ **Label Smoothing** - Prevents overfitting\n",
    "4. ‚úÖ **TTA** - Low-risk improvement (+1-2%)\n",
    "\n",
    "### Lessons Learned:\n",
    "\n",
    "We tested 5 complex experiments (ConvNeXt, EfficientNet, 512px):\n",
    "- Exp1 (ConvNeXt-Tiny, 288px): 76.15% ‚ùå\n",
    "- Exp2 (EfficientNetV2-S, 320px): 71.95% ‚ùå\n",
    "- **Baseline (ResNet18, 224px): 80.122% ‚úÖ**\n",
    "\n",
    "**Conclusion**: Simple configuration works best!\n",
    "\n",
    "### Next Steps to Reach 85%+ (Optional):\n",
    "\n",
    "1. **Train Multiple Models** - ResNet34, ResNet50\n",
    "2. **Soft Ensemble** - Average predictions from 3 models\n",
    "3. **Longer Training** - 20-30 epochs with early stopping\n",
    "4. **SWA** - Stochastic Weight Averaging\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You've successfully trained a model that matches the 80.122% baseline! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}