#!/bin/bash
# ğŸš€ ä¸¦è¡Œé›™è·¯å¾‘å† è»æµç¨‹
# è·¯å¾‘ A: NIH EfficientNet-V2-S (Stage 2-4, 5-Fold)
# è·¯å¾‘ B: EfficientNet-V2-L å½æ¨™ç±¤ (Stage 3-4, 1-Fold)

set -e

LOG_DIR="logs/parallel_execution"
mkdir -p $LOG_DIR

echo "================================================================================"
echo "ğŸš€ğŸš€ ä¸¦è¡Œé›™è·¯å¾‘å† è»æµç¨‹å•Ÿå‹• ğŸš€ğŸš€"
echo "================================================================================"
echo "é–‹å§‹æ™‚é–“: $(date)"
echo "ç­–ç•¥: äº¤éŒ¯åŸ·è¡Œï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡"
echo ""

# ============================================================================
# Phase 1: è·¯å¾‘ A - NIH Stage 2 (5-Fold) - ä¸»åŠ›è·¯å¾‘
# ============================================================================

echo "================================================================================"
echo "ğŸ“¦ Phase 1: è·¯å¾‘ A - NIH Stage 2 å¾®èª¿ (5-Fold)"
echo "================================================================================"
echo "æ¨¡å‹: EfficientNet-V2-S (20M åƒæ•¸)"
echo "é è¨“ç·´: NIH ChestX-ray14 (112K æ¨£æœ¬, Val AUC 85.55%)"
echo "é è¨ˆæ™‚é–“: 10-15 å°æ™‚ (5 folds Ã— 2-3 å°æ™‚/fold)"
echo ""

for fold in {0..4}; do
    echo "----------------------------------------"
    echo "ğŸ”„ NIH Stage 2 - Fold $fold / 4"
    echo "----------------------------------------"

    START_TIME=$(date +%s)

    # è¨“ç·´
    python3 train_breakthrough.py \
        --config configs/stage2_finetune.yaml \
        --fold $fold \
        > $LOG_DIR/nih_stage2_fold${fold}_$(date +%Y%m%d_%H%M%S).log 2>&1

    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))

    echo "âœ… NIH Stage 2 Fold $fold å®Œæˆï¼è€—æ™‚: $((DURATION/60)) åˆ†é˜"

    # æª¢æŸ¥ä¸¦é‡å‘½å
    if [ -f "outputs/stage2_finetune/best.pt" ]; then
        mkdir -p outputs/nih_v2s_stage2
        mv outputs/stage2_finetune/best.pt outputs/nih_v2s_stage2/fold${fold}_best.pt
        echo "   æ¨¡å‹å·²ä¿å­˜: outputs/nih_v2s_stage2/fold${fold}_best.pt"
    else
        echo "âŒ Fold $fold è¨“ç·´å¤±æ•—ï¼"
        exit 1
    fi

    echo ""
done

echo "âœ… Phase 1 å®Œæˆï¼æ‰€æœ‰ NIH Stage 2 æ¨¡å‹å·²è¨“ç·´"
echo ""

# ============================================================================
# Phase 2: ä¸¦è¡Œç”Ÿæˆå½æ¨™ç±¤
# ============================================================================

echo "================================================================================"
echo "ğŸ·ï¸ Phase 2: ä¸¦è¡Œç”Ÿæˆå½æ¨™ç±¤"
echo "================================================================================"
echo ""

# è·¯å¾‘ A: ä½¿ç”¨ NIH Stage 2 æ¨¡å‹
echo "ğŸ”„ è·¯å¾‘ A: ä½¿ç”¨ NIH Stage 2 (5 models) ç”Ÿæˆå½æ¨™ç±¤..."
python3 scripts/generate_pseudo_nih.py \
    --model_dir outputs/nih_v2s_stage2 \
    --model_arch efficientnet_v2_s \
    --output data/pseudo_labels_nih/high_conf.csv \
    --threshold 0.95 \
    > $LOG_DIR/pseudo_nih_$(date +%Y%m%d_%H%M%S).log 2>&1 &

PID_PSEUDO_A=$!
echo "   PID: $PID_PSEUDO_A"

# è·¯å¾‘ B: ä½¿ç”¨ V2-L æ¨¡å‹
echo "ğŸ”„ è·¯å¾‘ B: ä½¿ç”¨ V2-L (1 model) ç”Ÿæˆå½æ¨™ç±¤..."
python3 scripts/generate_pseudo_nih.py \
    --model_dir outputs/stage2_finetune \
    --model_arch efficientnet_v2_l \
    --output data/pseudo_labels_v2l/high_conf.csv \
    --threshold 0.95 \
    > $LOG_DIR/pseudo_v2l_$(date +%Y%m%d_%H%M%S).log 2>&1 &

PID_PSEUDO_B=$!
echo "   PID: $PID_PSEUDO_B"

# ç­‰å¾…å…©å€‹éƒ½å®Œæˆ
echo ""
echo "â³ ç­‰å¾…å½æ¨™ç±¤ç”Ÿæˆå®Œæˆ..."
wait $PID_PSEUDO_A
echo "âœ… è·¯å¾‘ A å½æ¨™ç±¤å®Œæˆ"
wait $PID_PSEUDO_B
echo "âœ… è·¯å¾‘ B å½æ¨™ç±¤å®Œæˆ"

echo ""
echo "âœ… Phase 2 å®Œæˆï¼å½æ¨™ç±¤å·²ç”Ÿæˆ"
echo ""

# ============================================================================
# Phase 3: å‰µå»ºæ“´å¢è¨“ç·´é›†
# ============================================================================

echo "================================================================================"
echo "ğŸ“š Phase 3: å‰µå»ºæ“´å¢è¨“ç·´é›†"
echo "================================================================================"
echo ""

# å‰µå»ºåˆä½µè…³æœ¬
cat > scripts/merge_pseudo_labels.py << 'MERGE_SCRIPT'
#!/usr/bin/env python3
"""åˆä½µåŸå§‹è¨“ç·´æ•¸æ“šå’Œå½æ¨™ç±¤"""

import pandas as pd
from pathlib import Path

kfold_dir = Path('data/kfold_splits')

# è·¯å¾‘ A: NIH å½æ¨™ç±¤
pseudo_nih = pd.read_csv('data/pseudo_labels_nih/high_conf.csv')
print(f"NIH å½æ¨™ç±¤: {len(pseudo_nih)} æ¨£æœ¬")

# è·¯å¾‘ B: V2-L å½æ¨™ç±¤
pseudo_v2l = pd.read_csv('data/pseudo_labels_v2l/high_conf.csv')
print(f"V2-L å½æ¨™ç±¤: {len(pseudo_v2l)} æ¨£æœ¬")

# åˆä½µå…©å€‹å½æ¨™ç±¤ï¼ˆå–äº¤é›†ä»¥ç¢ºä¿é«˜è³ªé‡ï¼‰
# åªä¿ç•™å…©å€‹æ¨¡å‹éƒ½é æ¸¬ç‚ºç›¸åŒé¡åˆ¥çš„æ¨£æœ¬
merged_pseudo = []

for idx, row_nih in pseudo_nih.iterrows():
    # æ‰¾åˆ°å°æ‡‰çš„ V2-L é æ¸¬
    row_v2l = pseudo_v2l[pseudo_v2l['new_filename'] == row_nih['new_filename']]

    if len(row_v2l) > 0:
        row_v2l = row_v2l.iloc[0]

        # æª¢æŸ¥é æ¸¬æ˜¯å¦ä¸€è‡´
        class_cols = ['normal', 'bacteria', 'virus', 'COVID-19']
        pred_nih = [row_nih[col] for col in class_cols]
        pred_v2l = [row_v2l[col] for col in class_cols]

        if pred_nih == pred_v2l:
            # å–å¹³å‡ç½®ä¿¡åº¦
            row_nih_copy = row_nih.copy()
            row_nih_copy['confidence'] = (row_nih['confidence'] + row_v2l['confidence']) / 2
            merged_pseudo.append(row_nih_copy)

merged_pseudo_df = pd.DataFrame(merged_pseudo)
print(f"åˆä½µå¾Œé«˜è³ªé‡å½æ¨™ç±¤: {len(merged_pseudo_df)} æ¨£æœ¬ (å…©æ¨¡å‹ä¸€è‡´)")

# ç‚ºæ¯å€‹ fold å‰µå»ºæ“´å¢æ•¸æ“šé›†
for fold in range(5):
    train_df = pd.read_csv(kfold_dir / f'fold{fold}_train.csv')

    # NIH è·¯å¾‘: ä½¿ç”¨åˆä½µçš„é«˜è³ªé‡å½æ¨™ç±¤
    augmented_nih = pd.concat([train_df, merged_pseudo_df], ignore_index=True)
    output_nih = kfold_dir / f'fold{fold}_train_nih_augmented.csv'
    augmented_nih.to_csv(output_nih, index=False)
    print(f"âœ… NIH Fold {fold}: {len(train_df)} + {len(merged_pseudo_df)} = {len(augmented_nih)} æ¨£æœ¬")

# V2-L è·¯å¾‘: åªç‚º fold 0 å‰µå»ºï¼ˆå¿«é€Ÿæ¸¬è©¦ï¼‰
train_df = pd.read_csv(kfold_dir / 'fold0_train.csv')
augmented_v2l = pd.concat([train_df, pseudo_v2l], ignore_index=True)
output_v2l = kfold_dir / 'fold0_train_v2l_augmented.csv'
augmented_v2l.to_csv(output_v2l, index=False)
print(f"âœ… V2-L Fold 0: {len(train_df)} + {len(pseudo_v2l)} = {len(augmented_v2l)} æ¨£æœ¬")

print("âœ… æ‰€æœ‰æ“´å¢æ•¸æ“šé›†å·²å‰µå»ºï¼")
MERGE_SCRIPT

chmod +x scripts/merge_pseudo_labels.py
python3 scripts/merge_pseudo_labels.py

echo "âœ… Phase 3 å®Œæˆï¼æ“´å¢è¨“ç·´é›†å·²å‰µå»º"
echo ""

# ============================================================================
# Phase 4: Stage 4 å½æ¨™ç±¤è¨“ç·´
# ============================================================================

echo "================================================================================"
echo "ğŸ“ Phase 4: Stage 4 å½æ¨™ç±¤è¨“ç·´"
echo "================================================================================"
echo ""

# å‰µå»º Stage 4 é…ç½®
cat > configs/stage4_nih_pseudo.yaml << 'STAGE4_NIH'
model: efficientnet_v2_s
img_size: 384
num_classes: 4
dropout: 0.3

# ä½¿ç”¨ NIH Stage 1 ä½œç‚ºåˆå§‹åŒ–ï¼ˆæ›´å¥½çš„èµ·é»ï¼‰
pretrained_checkpoint: outputs/pretrain_nih_stage1/best.pt

fold: 0
kfold_csv_dir: data/kfold_splits
data_dir: .

epochs: 30
batch_size: 24
num_workers: 12

optimizer: adamw
lr: 0.00008
weight_decay: 0.00015
warmup_epochs: 3

scheduler: cosine
min_lr: 0.000001

loss_type: improved_focal
focal_alpha: [1.0, 1.5, 2.0, 12.0]
focal_gamma: 3.5
label_smoothing: 0.12

mixup_prob: 0.5
mixup_alpha: 1.2
cutmix_prob: 0.5
aug_rotation: 18
random_erasing_prob: 0.3

use_swa: true
swa_start_epoch: 22
swa_lr: 0.00004

early_stopping: true
patience: 10

output_dir: outputs/nih_v2s_stage4
save_best: true
STAGE4_NIH

cat > configs/stage4_v2l_pseudo.yaml << 'STAGE4_V2L'
model: efficientnet_v2_l
img_size: 384
num_classes: 4
dropout: 0.3

# ä½¿ç”¨å‰›è¨“ç·´çš„ Stage 2 ä½œç‚ºåˆå§‹åŒ–
pretrained_checkpoint: outputs/stage2_finetune/best.pt

fold: 0
kfold_csv_dir: data/kfold_splits
data_dir: .

epochs: 25
batch_size: 16
num_workers: 12

optimizer: adamw
lr: 0.00005
weight_decay: 0.00015
warmup_epochs: 2

scheduler: cosine
min_lr: 0.000001

loss_type: improved_focal
focal_alpha: [1.0, 1.5, 2.0, 12.0]
focal_gamma: 3.5
label_smoothing: 0.12

mixup_prob: 0.5
cutmix_prob: 0.5
aug_rotation: 18
random_erasing_prob: 0.3

use_swa: true
swa_start_epoch: 18
swa_lr: 0.00003

early_stopping: true
patience: 10

output_dir: outputs/v2l_pseudo_stage4
save_best: true
STAGE4_V2L

# è·¯å¾‘ A: NIH Stage 4 (5-Fold) - ä¸»åŠ›
echo "ğŸ”„ è·¯å¾‘ A: NIH Stage 4 è¨“ç·´ (5-Fold)..."
for fold in {0..4}; do
    echo "   Training NIH Fold $fold..."

    # è‡¨æ™‚ä¿®æ”¹é…ç½®ä»¥ä½¿ç”¨æ“´å¢æ•¸æ“š
    python3 << EOF
import yaml
with open('configs/stage4_nih_pseudo.yaml', 'r') as f:
    cfg = yaml.safe_load(f)
cfg['fold'] = $fold
with open('configs/stage4_nih_pseudo_fold${fold}.yaml', 'w') as f:
    yaml.dump(cfg, f)

# ä¿®æ”¹ K-Fold CSV ä»¥ä½¿ç”¨æ“´å¢æ•¸æ“š
import pandas as pd
train_df = pd.read_csv('data/kfold_splits/fold${fold}_train_nih_augmented.csv')
# ç¢ºä¿è·¯å¾‘æ­£ç¢º
print(f"Fold $fold è¨“ç·´æ¨£æœ¬: {len(train_df)}")
EOF

    # è¨“ç·´
    python3 train_breakthrough.py \
        --config configs/stage4_nih_pseudo_fold${fold}.yaml \
        --fold $fold \
        > $LOG_DIR/nih_stage4_fold${fold}_$(date +%Y%m%d_%H%M%S).log 2>&1

    # ä¿å­˜æ¨¡å‹
    if [ -f "outputs/nih_v2s_stage4/best.pt" ]; then
        cp outputs/nih_v2s_stage4/best.pt outputs/nih_v2s_stage4/fold${fold}_best.pt
        echo "   âœ… NIH Stage 4 Fold $fold å®Œæˆ"
    fi
done

echo ""
echo "ğŸ”„ è·¯å¾‘ B: V2-L Stage 4 è¨“ç·´ (Fold 0)..."

# è·¯å¾‘ B: V2-L Stage 4 (åªè¨“ç·´ Fold 0 ä½œç‚ºæ¸¬è©¦)
python3 << EOF
import yaml
with open('configs/stage4_v2l_pseudo.yaml', 'r') as f:
    cfg = yaml.safe_load(f)
cfg['fold'] = 0
with open('configs/stage4_v2l_pseudo_fold0.yaml', 'w') as f:
    yaml.dump(cfg, f)
EOF

python3 train_breakthrough.py \
    --config configs/stage4_v2l_pseudo_fold0.yaml \
    --fold 0 \
    > $LOG_DIR/v2l_stage4_fold0_$(date +%Y%m%d_%H%M%S).log 2>&1

if [ -f "outputs/v2l_pseudo_stage4/best.pt" ]; then
    cp outputs/v2l_pseudo_stage4/best.pt outputs/v2l_pseudo_stage4/fold0_best.pt
    echo "   âœ… V2-L Stage 4 Fold 0 å®Œæˆ"
fi

echo ""
echo "âœ… Phase 4 å®Œæˆï¼æ‰€æœ‰ Stage 4 æ¨¡å‹å·²è¨“ç·´"
echo ""

# ============================================================================
# Phase 5: ç”Ÿæˆæœ€çµ‚é æ¸¬
# ============================================================================

echo "================================================================================"
echo "ğŸ¯ Phase 5: ç”Ÿæˆæœ€çµ‚é æ¸¬"
echo "================================================================================"
echo ""

# å‰µå»ºæœ€çµ‚é æ¸¬è…³æœ¬
cat > scripts/generate_final_predictions.py << 'FINAL_PRED'
#!/usr/bin/env python3
"""ç”Ÿæˆæœ€çµ‚é›†æˆé æ¸¬"""

import sys
import torch
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
from torch.utils.data import DataLoader

sys.path.insert(0, str(Path(__file__).parent.parent))
from train_breakthrough import build_model
from scripts.generate_pseudo_nih import TestDataset

@torch.no_grad()
def generate_predictions(models_config, test_csv, test_images, output_csv):
    """ç”Ÿæˆæœ€çµ‚é æ¸¬"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # åŠ è¼‰æ•¸æ“š
    test_dataset = TestDataset(test_csv, test_images, img_size=384)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=True)

    all_probs = []

    for model_info in models_config:
        model_paths = model_info['paths']
        model_arch = model_info['arch']
        weight = model_info['weight']

        print(f"\nè™•ç†: {model_arch} ({len(model_paths)} models, weight={weight})")

        fold_probs_list = []

        for model_path in model_paths:
            model = build_model(model_arch, num_classes=4, dropout=0.3, img_size=384)
            checkpoint = torch.load(model_path, map_location='cpu')

            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)

            model = model.to(device)
            model.eval()

            fold_probs = []
            for images, _ in tqdm(test_loader, desc=f"é æ¸¬ {Path(model_path).name}"):
                images = images.to(device)
                outputs = model(images)
                probs = torch.softmax(outputs, dim=1).cpu().numpy()
                fold_probs.append(probs)

            fold_probs = np.concatenate(fold_probs, axis=0)
            fold_probs_list.append(fold_probs)

            del model
            torch.cuda.empty_cache()

        # å¹³å‡æ­¤é¡æ¨¡å‹çš„é æ¸¬
        avg_probs = np.mean(fold_probs_list, axis=0)
        # æ‡‰ç”¨æ¬Šé‡
        weighted_probs = avg_probs * weight
        all_probs.append(weighted_probs)

    # æœ€çµ‚é›†æˆ
    final_probs = np.sum(all_probs, axis=0)
    final_probs = final_probs / final_probs.sum(axis=1, keepdims=True)  # é‡æ–°æ­¸ä¸€åŒ–

    # ç”Ÿæˆæäº¤æ–‡ä»¶
    test_df = pd.read_csv(test_csv)
    pred_labels = np.argmax(final_probs, axis=1)

    class_names = ['normal', 'bacteria', 'virus', 'COVID-19']
    for i, class_name in enumerate(class_names):
        test_df[class_name] = (pred_labels == i).astype(int)

    test_df[['new_filename'] + class_names].to_csv(output_csv, index=False)
    print(f"\nâœ… æœ€çµ‚é æ¸¬å·²ä¿å­˜: {output_csv}")

    # çµ±è¨ˆ
    print("\né æ¸¬åˆ†å¸ƒ:")
    for i, class_name in enumerate(class_names):
        count = np.sum(pred_labels == i)
        print(f"  {class_name}: {count} ({100*count/len(test_df):.1f}%)")

if __name__ == '__main__':
    # é…ç½®æ‰€æœ‰æ¨¡å‹
    models_config = [
        {
            'paths': [f'outputs/nih_v2s_stage4/fold{i}_best.pt' for i in range(5)],
            'arch': 'efficientnet_v2_s',
            'weight': 0.50  # NIH Stage 4 (ä¸»åŠ›)
        },
        {
            'paths': [f'outputs/nih_v2s_stage2/fold{i}_best.pt' for i in range(5)],
            'arch': 'efficientnet_v2_s',
            'weight': 0.20  # NIH Stage 2
        },
        {
            'paths': ['outputs/v2l_pseudo_stage4/fold0_best.pt'],
            'arch': 'efficientnet_v2_l',
            'weight': 0.15  # V2-L Stage 4
        },
        {
            'paths': ['outputs/stage2_finetune/best.pt'],
            'arch': 'efficientnet_v2_l',
            'weight': 0.15  # V2-L Stage 2
        },
    ]

    generate_predictions(
        models_config=models_config,
        test_csv='data/test_data.csv',
        test_images='test_images',
        output_csv='data/submission_ultimate_parallel.csv'
    )
FINAL_PRED

chmod +x scripts/generate_final_predictions.py
python3 scripts/generate_final_predictions.py > $LOG_DIR/final_predictions_$(date +%Y%m%d_%H%M%S).log 2>&1

echo "âœ… Phase 5 å®Œæˆï¼æœ€çµ‚é æ¸¬å·²ç”Ÿæˆ"
echo ""

# ============================================================================
# å®Œæˆå ±å‘Š
# ============================================================================

echo "================================================================================"
echo "ğŸ‰ğŸ‰ğŸ‰ ä¸¦è¡Œé›™è·¯å¾‘æµç¨‹åŸ·è¡Œå®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰"
echo "================================================================================"
echo "å®Œæˆæ™‚é–“: $(date)"
echo ""
echo "è¼¸å‡ºæ¨¡å‹:"
echo "  è·¯å¾‘ A (NIH V2-S):"
echo "    Stage 2: outputs/nih_v2s_stage2/fold{0-4}_best.pt"
echo "    Stage 4: outputs/nih_v2s_stage4/fold{0-4}_best.pt"
echo ""
echo "  è·¯å¾‘ B (V2-L):"
echo "    Stage 4: outputs/v2l_pseudo_stage4/fold0_best.pt"
echo ""
echo "æœ€çµ‚æäº¤:"
echo "  data/submission_ultimate_parallel.csv"
echo ""
echo "ä¸‹ä¸€æ­¥: æäº¤è‡³ Kaggleï¼"
echo "================================================================================"
