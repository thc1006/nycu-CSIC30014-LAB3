#!/usr/bin/env python3
"""
Stage 1: NIH ChestX-ray14 å¤šæ¨™ç±¤é è¨“ç·´
ç¬¬1åæ ¸å¿ƒæŠ€å·§ - åœ¨å¤§è¦æ¨¡å¤–éƒ¨æ•¸æ“šä¸Šé è¨“ç·´ç‰¹å¾µæå–å™¨

é æœŸæ•ˆæœ: +3-5% åœ¨ç›®æ¨™ä»»å‹™ä¸Š
è¨“ç·´æ™‚é–“: 18-20å°æ™‚ (10 epochs, 77K æ¨£æœ¬)
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import argparse
from sklearn.metrics import roc_auc_score

# 14ç¨®ç–¾ç—…æ¨™ç±¤
DISEASE_LABELS = [
    'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration',
    'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax',
    'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',
    'Pleural_Thickening', 'Hernia'
]

class NIHChestXrayDataset(Dataset):
    """NIH ChestX-ray14 å¤šæ¨™ç±¤æ•¸æ“šé›†"""

    def __init__(self, csv_path, transform=None):
        self.df = pd.read_csv(csv_path)
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # è®€å–å½±åƒ
        img_path = Path(row['image_path']) / row['Image Index']
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        # å¤šæ¨™ç±¤ï¼ˆ14ç¶­ binary vectorï¼‰
        labels = row[DISEASE_LABELS].values.astype(np.float32)
        labels = torch.from_numpy(labels)

        return image, labels


def create_transforms(img_size=384, augment=True):
    """å‰µå»ºæ•¸æ“šå¢å¼·"""
    if augment:
        return transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
    else:
        return transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])


def build_model(model_name='efficientnet_v2_s', num_classes=14):
    """
    æ§‹å»ºæ¨¡å‹
    ä½¿ç”¨ ImageNet é è¨“ç·´æ¬Šé‡åˆå§‹åŒ–
    """
    if model_name == 'efficientnet_v2_s':
        model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)
        # æ›¿æ›åˆ†é¡é ­ç‚ºå¤šæ¨™ç±¤åˆ†é¡
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Linear(in_features, num_classes)
    else:
        raise ValueError(f"Unknown model: {model_name}")

    return model


def train_epoch(model, loader, criterion, optimizer, device, scaler=None):
    """è¨“ç·´ä¸€å€‹ epoch"""
    model.train()
    total_loss = 0

    pbar = tqdm(loader, desc='Training')
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        # æ··åˆç²¾åº¦è¨“ç·´
        if scaler is not None:
            with torch.cuda.amp.autocast():
                outputs = model(images)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        total_loss += loss.item()
        pbar.set_postfix({'loss': loss.item()})

    return total_loss / len(loader)


@torch.no_grad()
def validate(model, loader, criterion, device):
    """é©—è­‰"""
    model.eval()
    total_loss = 0
    all_labels = []
    all_preds = []

    for images, labels in tqdm(loader, desc='Validating'):
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        total_loss += loss.item()

        # æ”¶é›†é æ¸¬å’Œæ¨™ç±¤ç”¨æ–¼è¨ˆç®— AUC
        all_labels.append(labels.cpu().numpy())
        all_preds.append(torch.sigmoid(outputs).cpu().numpy())

    all_labels = np.concatenate(all_labels, axis=0)
    all_preds = np.concatenate(all_preds, axis=0)

    # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„ AUC
    auc_scores = []
    for i in range(len(DISEASE_LABELS)):
        if all_labels[:, i].sum() > 0:  # åªè¨ˆç®—æœ‰æ­£æ¨£æœ¬çš„é¡åˆ¥
            auc = roc_auc_score(all_labels[:, i], all_preds[:, i])
            auc_scores.append(auc)

    mean_auc = np.mean(auc_scores) if auc_scores else 0.0

    return total_loss / len(loader), mean_auc


def main(args):
    print("=" * 80)
    print("ğŸ† Stage 1: NIH ChestX-ray14 å¤šæ¨™ç±¤é è¨“ç·´")
    print("ç¬¬1åæ ¸å¿ƒæŠ€å·§ - å¤–éƒ¨æ•¸æ“šé è¨“ç·´")
    print("=" * 80)

    # è¨­å‚™
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nè¨­å‚™: {device}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")

    # æ•¸æ“šé›†
    project_root = Path(__file__).parent.parent
    nih_processed = project_root / 'data' / 'external' / 'nih_chestxray14' / 'processed'

    print(f"\nè¼‰å…¥æ•¸æ“šé›†...")
    train_dataset = NIHChestXrayDataset(
        csv_path=nih_processed / 'train.csv',
        transform=create_transforms(img_size=args.img_size, augment=True)
    )
    val_dataset = NIHChestXrayDataset(
        csv_path=nih_processed / 'val.csv',
        transform=create_transforms(img_size=args.img_size, augment=False)
    )

    print(f"  è¨“ç·´: {len(train_dataset)} æ¨£æœ¬")
    print(f"  é©—è­‰: {len(val_dataset)} æ¨£æœ¬")

    # DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True
    )

    # æ¨¡å‹
    print(f"\næ§‹å»ºæ¨¡å‹: {args.model}")
    model = build_model(model_name=args.model, num_classes=14)
    model = model.to(device)

    # è¨ˆç®—åƒæ•¸é‡
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  ç¸½åƒæ•¸: {total_params:,}")

    # Loss & Optimizer
    criterion = nn.BCEWithLogitsLoss()  # å¤šæ¨™ç±¤åˆ†é¡
    optimizer = optim.AdamW(
        model.parameters(),
        lr=args.lr,
        weight_decay=args.weight_decay
    )

    # å­¸ç¿’ç‡èª¿åº¦
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=args.epochs,
        eta_min=args.lr / 100
    )

    # æ··åˆç²¾åº¦
    scaler = torch.cuda.amp.GradScaler() if args.use_amp else None

    # è¨“ç·´
    print(f"\né–‹å§‹è¨“ç·´ {args.epochs} epochs...")
    best_auc = 0.0
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    for epoch in range(args.epochs):
        print(f"\n{'='*80}")
        print(f"Epoch {epoch + 1}/{args.epochs}")
        print(f"{'='*80}")

        # è¨“ç·´
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler)

        # é©—è­‰
        val_loss, val_auc = validate(model, val_loader, criterion, device)

        # å­¸ç¿’ç‡èª¿æ•´
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']

        print(f"\nEpoch {epoch + 1} çµæœ:")
        print(f"  Train Loss: {train_loss:.4f}")
        print(f"  Val Loss:   {val_loss:.4f}")
        print(f"  Val AUC:    {val_auc:.4f}")
        print(f"  LR:         {current_lr:.6f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_auc > best_auc:
            best_auc = val_auc
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_auc': val_auc,
                'val_loss': val_loss,
                'config': {
                    'model': args.model,
                    'img_size': args.img_size,
                    'num_classes': 14
                }
            }
            torch.save(checkpoint, output_dir / 'best.pt')
            print(f"  âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (AUC: {val_auc:.4f})")

    print("\n" + "=" * 80)
    print("ğŸ‰ Stage 1 é è¨“ç·´å®Œæˆï¼")
    print(f"æœ€ä½³é©—è­‰ AUC: {best_auc:.4f}")
    print(f"æ¨¡å‹ä¿å­˜è‡³: {output_dir / 'best.pt'}")
    print("\nä¸‹ä¸€æ­¥:")
    print("  python3 scripts/train_finetune_target.py \\")
    print(f"    --pretrained {output_dir / 'best.pt'}")
    print("=" * 80)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', default='efficientnet_v2_s')
    parser.add_argument('--img-size', type=int, default=384)
    parser.add_argument('--epochs', type=int, default=10)
    parser.add_argument('--batch-size', type=int, default=32)
    parser.add_argument('--lr', type=float, default=0.0001)
    parser.add_argument('--weight-decay', type=float, default=0.0001)
    parser.add_argument('--num-workers', type=int, default=4)
    parser.add_argument('--use-amp', action='store_true', default=True)
    parser.add_argument('--output-dir', default='outputs/pretrain_nih_stage1')

    args = parser.parse_args()
    main(args)
