#!/usr/bin/env python3
"""
ç”Ÿæˆè¶…é«˜ç½®ä¿¡åº¦æ¸¬è©¦é›†å½æ¨™ç±¤
ç­–ç•¥ï¼šä¸‰å€‹æœ€ä½³æ¨¡å‹æŠ•ç¥¨ + ç½®ä¿¡åº¦ â‰¥0.99
"""

import pandas as pd
import numpy as np

def load_predictions_as_probs(csv_path):
    """è¼‰å…¥é æ¸¬ä¸¦è½‰æ›ç‚ºæ¦‚ç‡ï¼ˆå¦‚æœæ˜¯ one-hotï¼‰"""
    df = pd.read_csv(csv_path)
    class_cols = ['normal', 'bacteria', 'virus', 'COVID-19']

    probs = df[class_cols].values

    # æª¢æŸ¥æ˜¯å¦ç‚º one-hot (æ‰€æœ‰å€¼éƒ½æ˜¯ 0 æˆ– 1)
    is_onehot = np.all((probs == 0) | (probs == 1))

    if is_onehot:
        print(f"  âš ï¸  {csv_path.split('/')[-1]} æ˜¯ one-hot æ ¼å¼ï¼Œéœ€è¦æ¦‚ç‡ç‰ˆæœ¬")
        return None

    return df

def main():
    print("="*70)
    print("ğŸ” ç”Ÿæˆè¶…é«˜ç½®ä¿¡åº¦æ¸¬è©¦é›†å½æ¨™ç±¤")
    print("="*70)

    # ä½¿ç”¨å¯ç”¨çš„æ¦‚ç‡æ ¼å¼é æ¸¬æ–‡ä»¶
    model_files = {
        'V2-L 512 Ensemble': 'data/submission_v2l_512_ensemble.csv',
        'V2-L 512 (50-50)': 'data/submission_v2l50_best50.csv',
        'V2-L 512 (60-40)': 'data/submission_v2l60_best40.csv',
    }

    # è¼‰å…¥é æ¸¬
    predictions = {}
    class_cols = ['normal', 'bacteria', 'virus', 'COVID-19']

    print("\nğŸ“‚ è¼‰å…¥æ¨¡å‹é æ¸¬...")
    for name, path in model_files.items():
        df = load_predictions_as_probs(path)
        if df is not None:
            predictions[name] = df
            max_conf = df[class_cols].max(axis=1).mean()
            print(f"  âœ… {name}: {len(df)} å¼µï¼Œå¹³å‡æœ€å¤§ç½®ä¿¡åº¦ {max_conf:.4f}")
        else:
            print(f"  âŒ {name}: æ ¼å¼ä¸æ­£ç¢ºï¼Œè·³é")

    if len(predictions) < 2:
        print("\nâŒ è‡³å°‘éœ€è¦ 2 å€‹æ¨¡å‹çš„æ¦‚ç‡é æ¸¬ï¼")
        print("\nğŸ’¡ è§£æ±ºæ–¹æ¡ˆï¼šä½¿ç”¨ä»¥ä¸‹æ–‡ä»¶ï¼ˆå·²æ˜¯æ¦‚ç‡æ ¼å¼ï¼‰")
        print("  â€¢ data/submission_v2l50_best50.csv (V2-L 512 æ¦‚ç‡ç‰ˆæœ¬)")
        print("  â€¢ data/submission_v2l_512_ensemble.csv (V2-L ç´”é›†æˆ)")
        print("\n  æˆ–é‡æ–°ç”Ÿæˆ Hybrid Adaptive çš„æ¦‚ç‡ç‰ˆæœ¬")
        return

    # å–å¾—æ¨£æœ¬æ•¸é‡
    n_samples = len(list(predictions.values())[0])
    filenames = list(predictions.values())[0]['new_filename'].values

    # è¨ˆç®—æ¯å€‹æ¨£æœ¬çš„ï¼š1) é æ¸¬é¡åˆ¥ï¼Œ2) ç½®ä¿¡åº¦
    all_pred_classes = []
    all_confidences = []

    for name, df in predictions.items():
        probs = df[class_cols].values
        pred_classes = np.argmax(probs, axis=1)
        confidences = np.max(probs, axis=1)
        all_pred_classes.append(pred_classes)
        all_confidences.append(confidences)

    all_pred_classes = np.array(all_pred_classes)  # (n_models, n_samples)
    all_confidences = np.array(all_confidences)    # (n_models, n_samples)

    # è¨ˆç®—å¹³å‡ç½®ä¿¡åº¦å’Œä¸€è‡´æ€§
    avg_confidence = np.mean(all_confidences, axis=0)

    # æª¢æŸ¥æ‰€æœ‰æ¨¡å‹é æ¸¬æ˜¯å¦ä¸€è‡´
    if len(predictions) == 3:
        consistent = (all_pred_classes[0] == all_pred_classes[1]) & \
                     (all_pred_classes[1] == all_pred_classes[2])
    else:  # 2 å€‹æ¨¡å‹
        consistent = (all_pred_classes[0] == all_pred_classes[1])

    print(f"\nğŸ“Š çµ±è¨ˆåˆ†æ")
    print(f"  ç¸½æ¨£æœ¬æ•¸: {n_samples}")
    print(f"  æ¨¡å‹ä¸€è‡´çš„æ¨£æœ¬: {consistent.sum()} ({consistent.sum()/n_samples*100:.1f}%)")
    print(f"  å¹³å‡ç½®ä¿¡åº¦ â‰¥0.99: {(avg_confidence >= 0.99).sum()} ({(avg_confidence >= 0.99).sum()/n_samples*100:.1f}%)")

    # ç¯©é¸ï¼šä¸€è‡´ + é«˜ç½®ä¿¡åº¦
    mask_normal = consistent & (avg_confidence >= 0.99)
    mask_covid = consistent & (avg_confidence >= 0.95) & (all_pred_classes[0] == 3)  # COVID-19 æ”¾å¯¬

    final_mask = mask_normal | mask_covid

    print(f"\nâœ… æœ€çµ‚ç¯©é¸çµæœ:")
    print(f"  ä¸€èˆ¬é¡åˆ¥ (conf â‰¥0.99): {mask_normal.sum()}")
    print(f"  COVID-19 (conf â‰¥0.95): {mask_covid.sum()}")
    print(f"  ç¸½è¨ˆé«˜ç½®ä¿¡åº¦æ¨£æœ¬: {final_mask.sum()} ({final_mask.sum()/n_samples*100:.1f}%)")

    # å‰µå»ºå½æ¨™ç±¤æ•¸æ“šé›†
    selected_filenames = filenames[final_mask]
    selected_classes = all_pred_classes[0][final_mask]
    selected_confidences = avg_confidence[final_mask]

    # æ§‹å»º DataFrame
    pseudo_df = pd.DataFrame({
        'new_filename': selected_filenames,
        'label': selected_classes,
        'confidence': selected_confidences
    })

    # æ·»åŠ  one-hot åˆ—
    for i, col in enumerate(class_cols):
        pseudo_df[col] = (pseudo_df['label'] == i).astype(int)

    # æŒ‰é¡åˆ¥çµ±è¨ˆ
    print(f"\nğŸ“ˆ å½æ¨™ç±¤é¡åˆ¥åˆ†å¸ƒ:")
    for i, col in enumerate(class_cols):
        count = (pseudo_df['label'] == i).sum()
        print(f"  {col}: {count} ({count/len(pseudo_df)*100:.1f}%)")

    # ä¿å­˜
    output_path = 'data/test_pseudo_labels_ultra_high_conf.csv'
    pseudo_df.to_csv(output_path, index=False)

    print(f"\nâœ… å½æ¨™ç±¤å·²ä¿å­˜: {output_path}")
    print(f"   æ¨£æœ¬æ•¸: {len(pseudo_df)}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {pseudo_df['confidence'].mean():.4f}")
    print(f"   æœ€ä½ç½®ä¿¡åº¦: {pseudo_df['confidence'].min():.4f}")

    # ä¿å­˜çµ±è¨ˆå ±å‘Š
    with open('data/pseudo_labels_stats.txt', 'w') as f:
        f.write(f"è¶…é«˜ç½®ä¿¡åº¦å½æ¨™ç±¤çµ±è¨ˆå ±å‘Š\n")
        f.write(f"{'='*60}\n\n")
        f.write(f"ç”Ÿæˆæ™‚é–“: 2025-11-15\n")
        f.write(f"ä¾†æºæ¨¡å‹: {', '.join(predictions.keys())}\n")
        f.write(f"æ¸¬è©¦é›†ç¸½æ•¸: {n_samples}\n")
        f.write(f"é«˜ç½®ä¿¡åº¦æ¨£æœ¬: {len(pseudo_df)} ({len(pseudo_df)/n_samples*100:.1f}%)\n\n")
        f.write(f"é¡åˆ¥åˆ†å¸ƒ:\n")
        for i, col in enumerate(class_cols):
            count = (pseudo_df['label'] == i).sum()
            f.write(f"  {col}: {count} ({count/len(pseudo_df)*100:.1f}%)\n")
        f.write(f"\nç½®ä¿¡åº¦çµ±è¨ˆ:\n")
        f.write(f"  å¹³å‡: {pseudo_df['confidence'].mean():.4f}\n")
        f.write(f"  æœ€å°: {pseudo_df['confidence'].min():.4f}\n")
        f.write(f"  æœ€å¤§: {pseudo_df['confidence'].max():.4f}\n")

    print(f"   çµ±è¨ˆå ±å‘Š: data/pseudo_labels_stats.txt")

    print(f"\n{'='*70}")
    print("ğŸ‰ Phase 1 å®Œæˆï¼")
    print(f"{'='*70}")
    print("\nä¸‹ä¸€æ­¥: Phase 2 - åˆä½µåˆ°è¨“ç·´é›†")

if __name__ == "__main__":
    main()
