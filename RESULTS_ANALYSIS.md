# 實驗結果分析

## 📊 Kaggle 提交結果

### 實驗 1: ConvNeXt-Tiny
- **配置**: configs/exp1_convnext_tiny.yaml
- **模型**: ConvNeXt-Tiny @ 288px
- **訓練**: 25 epochs
- **驗證 F1**: ~0.80 (估計，基於訓練日誌)
- **Kaggle Public Score**: **0.76148 (76.15%)**

### 實驗 2: EfficientNetV2-S
- **配置**: configs/exp2_efficientnetv2.yaml
- **模型**: EfficientNetV2-S @ 320px + SWA
- **訓練**: 30 epochs
- **驗證 F1**: 0.7511 (75.11%)
- **Kaggle Public Score**: **0.7195 (71.95%)** ❌ WORSE than expected

### ⚠️ 原始基準線 (Baseline)
- **檔案**: data/submission.csv
- **來源**: 先前本地訓練的模型
- **Kaggle Public Score**: **0.80 (80.00%)** ✅ BEST

## 🔍 分析

### 1. 驗證集 vs Public Leaderboard
- **原始基準**: 未知 Val F1 → Public **80.00%** ✅
- **Exp1**: 驗證 F1 ~80% → Public **76.15%** (↓ 3.85%)
- **Exp2**: 驗證 F1 75.11% → Public **71.95%** (↓ 3.16%)
- **差距**: 約 3-4% 的性能下降（驗證集→Public）
- **關鍵發現**: **新的實驗表現都比原始基準差！**

### 2. 預測差異分析
- **原始 vs Exp1**: 86.21% 一致性 (163/1182 samples 不同)
- **原始 vs Exp2**: 83.84% 一致性 (191/1182 samples 不同)
- **Exp1 vs Exp2**: 83.76% 一致性

**類別分佈差異**:
- **Normal**: 原始 28.0% vs Exp1 31.0% vs Exp2 25.7%
- **Bacteria**: 原始 39.3% vs Exp1 39.5% vs Exp2 36.3%
- **Virus**: 原始 31.3% vs Exp1 28.0% vs Exp2 35.6%
- **COVID-19**: 原始 1.4% vs Exp1 1.5% vs Exp2 2.4%

**關鍵錯誤類型**:
1. **Virus → Bacteria** 混淆 (Exp1/Exp2 的主要錯誤)
2. **Bacteria → Virus** 混淆
3. **Normal ←→ Bacteria** 混淆

### 3. 模型表現
**原始基準 (80.00%)**:
- ✅ **最佳表現** - 應作為主要提交
- 未知具體配置，但表現優於所有新實驗
- 可能使用更好的預訓練權重或訓練策略

**ConvNeXt-Tiny (Exp1 - 76.15%)**:
- ✓ 較新的架構，更好的歸納能力
- ✓ 288px 解析度平衡了細節與記憶體
- ✓ 25 epochs 避免過擬合
- ❌ 比原始基準差 3.85%

**EfficientNetV2-S (Exp2 - 71.95%)**:
- ✓ 更高解析度 (320px)
- ✓ 使用 SWA (理論上提升泛化能力)
- ✓ 30 epochs + 更強的正則化
- ❌ 比原始基準差 8.05%
- ❌ 比 Exp1 還差 4.20%

### 4. 改進空間與策略

**當前最佳**: 原始基準 80.00%
**目標**: 90%+ (需要提升 10%)

**立即可行** (低成本):
1. ✅ 保持使用原始基準 data/submission.csv (80.00%)
2. ⏳ 創建 3-way Ensemble (原始 + Exp1 + Exp2)
   - 預期: 可能達到 80-82%
   - 風險: 也可能因為 Exp2 太差而降低分數

**需要更多訓練**:
3. 實驗 3-5 (ResNet34, EfficientNet-B0, ResNet18)
   - 如果成功: 5 模型 ensemble 可能達到 78-82%
4. 更長訓練 (50+ epochs)
5. 更激進的數據增強
6. 針對 COVID-19 類別的特別優化

**進階策略** (達到 90%+):
- 使用更大的模型 (ResNet50, EfficientNet-B3+)
- 偽標籤 (Pseudo-labeling)
- 外部數據增強
- 模型蒸餾
- 更複雜的 Ensemble 策略

## 📈 預測提升路徑 (更新版)

| 方法 | 預期分數 | 實際分數 | 狀態 |
|------|---------|---------|------|
| **原始基準** | 80.00% | **80.00%** ✅ | **BEST** |
| Exp1 單模型 | 76-77% | 76.15% | ✅ 完成 |
| Exp2 單模型 | 76-77% | 71.95% ❌ | ✅ 完成 |
| 原始+Exp1 Ensemble (2-way) | 80-81% | ⏳ 待測試 | 推薦 |
| 原始+Exp1+Exp2 (3-way) | 79-82% | ⏳ 待測試 | 值得嘗試 |
| 5 模型 Ensemble | 78-82% | - | ❌ Exp3-5 失敗 |
| 重新訓練 Exp3-5 | 78-82% | - | ⏳ 可嘗試 |
| 進階優化 | 85-90%+ | - | 需大量工作 |

## 💡 下一步建議 (更新版)

### ⚠️ 重要發現
**原始基準 (80.00%) 優於所有新實驗！**
- Exp1: 76.15% (-3.85%)
- Exp2: 71.95% (-8.05%)

### 立即行動 (推薦):
1. ✅ **保持使用 data/submission.csv 作為主要提交** (80.00%)
2. ⏳ 創建 2-way Ensemble (原始 + Exp1)
   - 可能提升至 80-81%
3. ⏳ 創建 3-way Ensemble (原始 + Exp1 + Exp2)
   - 風險較高，因為 Exp2 表現較差

### 短期行動 (如果需要更高分數):
1. 重啟電腦，清理 GPU 狀態
2. 重新嘗試運行實驗 3-5
3. 或者使用已成功的配置 (exp1/exp2) 訓練更多模型變種

### 中長期行動:
1. 分析錯誤案例 (哪些圖片分類錯誤)
2. 針對性優化難分類的類別
3. 考慮使用更大的模型或 ensemble 更多模型

---

**結論** (更新):
- **原始基準 80.00% 是目前最佳結果** ✅
- 新訓練的模型 (Exp1: 76.15%, Exp2: 71.95%) 都**不如原始基準**
- Ensemble 可能略微提升，但不保證超過 80%
- 要達到 90%+ 需要：
  1. 了解原始 80% 模型的配置並重現
  2. 或採用更強的模型架構和訓練策略
  3. 可能需要數據增強、偽標籤、模型蒸餾等進階技術

**關鍵建議**:
- 優先使用原始 data/submission.csv (80.00%)
- Ensemble 作為實驗性嘗試，但不要過度期待

**最後更新**: 2025-10-12 (after Exp2 submission: 71.95%)
