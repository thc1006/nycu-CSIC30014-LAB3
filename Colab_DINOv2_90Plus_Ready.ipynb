{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸš€ èƒ¸éƒ¨ X å…‰ DINOv2 - çªç ´ 90% å®Œå…¨è‡ªå‹•åŒ–è¨“ç·´\n",
    "\n",
    "**ç•¶å‰æœ€ä½³**: 87.574% â†’ **ç›®æ¨™**: 90%+ (é æœŸ 89.5-91.5%)\n",
    "\n",
    "**ç­–ç•¥**: DINOv2 Vision Transformer (142M åœ–ç‰‡é è¨“ç·´)\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ å¿«é€Ÿé–‹å§‹\n",
    "\n",
    "### å¿…é ˆè¨­ç½®ï¼ˆé–‹å§‹å‰ï¼‰\n",
    "1. âœ… **å•Ÿç”¨ A100 GPU**: Runtime â†’ Change runtime type â†’ GPU â†’ A100\n",
    "2. âœ… **æº–å‚™ Kaggle API**: ä¸‹è¼‰ `kaggle.json` (Kaggle â†’ Account â†’ Create API Token)\n",
    "\n",
    "### åŸ·è¡Œé¸é …\n",
    "- **é¸é … A (æ¨è–¦)**: å¿«é€Ÿé©—è­‰ - åªè¨“ç·´ Fold 0 (2 å°æ™‚) â†’ é©—è­‰æ•ˆæœ\n",
    "- **é¸é … B**: å®Œæ•´è¨“ç·´ - æ‰€æœ‰ 5 Folds (8-10 å°æ™‚) â†’ ç›®æ¨™ 90%+\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š è³‡æ–™æµç¨‹\n",
    "```\n",
    "GitHub (ä»£ç¢¼) â†’ Colab SSD\n",
    "     â†“\n",
    "Kaggle (æ•¸æ“š 3.4GB) â†’ Colab SSD\n",
    "     â†“\n",
    "è¨“ç·´æ•¸æ“š â†’ A100 GPU (40GB)\n",
    "     â†“\n",
    "DINOv2 æ¨¡å‹ â†’ é æ¸¬ â†’ Kaggle æäº¤\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**é è¨ˆæ™‚é–“**: \n",
    "- ç’°å¢ƒè¨­ç½®: 5-10 åˆ†é˜\n",
    "- Fold 0 è¨“ç·´: 1.5-2 å°æ™‚ (A100)\n",
    "- 5-Fold å®Œæ•´: 7-10 å°æ™‚ (A100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## 1ï¸âƒ£ ç’°å¢ƒæª¢æŸ¥èˆ‡ GPU è¨­ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” ç’°å¢ƒæª¢æŸ¥\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Python ç‰ˆæœ¬\n",
    "import sys\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# PyTorch ç‰ˆæœ¬\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "\n",
    "# GPU æª¢æŸ¥\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"\\nâœ… GPU: {gpu_name}\")\n",
    "    print(f\"âœ… GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # æ¨è–¦é…ç½®\n",
    "    if \"A100\" in gpu_name:\n",
    "        batch_size = 32\n",
    "        print(f\"\\nğŸš€ æª¢æ¸¬åˆ° A100ï¼ä½¿ç”¨å„ªåŒ–é…ç½®:\")\n",
    "        print(f\"   - Batch Size: {batch_size}\")\n",
    "        print(f\"   - é è¨ˆè¨“ç·´æ™‚é–“: 1.5-2 å°æ™‚/fold\")\n",
    "    elif gpu_memory > 14:\n",
    "        batch_size = 16\n",
    "        print(f\"\\nâœ… æª¢æ¸¬åˆ° {gpu_memory:.0f}GB GPU\")\n",
    "        print(f\"   - Batch Size: {batch_size}\")\n",
    "        print(f\"   - é è¨ˆè¨“ç·´æ™‚é–“: 2-3 å°æ™‚/fold\")\n",
    "    else:\n",
    "        batch_size = 8\n",
    "        print(f\"\\nâš ï¸ GPU è¨˜æ†¶é«”è¼ƒå°\")\n",
    "        print(f\"   - Batch Size: {batch_size}\")\n",
    "        print(f\"   - é è¨ˆè¨“ç·´æ™‚é–“: 3-4 å°æ™‚/fold\")\n",
    "else:\n",
    "    print(\"\\nâŒ éŒ¯èª¤: æ²’æœ‰æª¢æ¸¬åˆ° GPUï¼\")\n",
    "    print(\"è«‹ç¢ºèª: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU\")\n",
    "    raise RuntimeError(\"No GPU detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ç’°å¢ƒæª¢æŸ¥å®Œæˆ\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## 2ï¸âƒ£ å®‰è£ä¾è³´å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# éœé»˜å®‰è£ï¼Œé¿å…éå¤šè¼¸å‡º\n",
    "\n",
    "# å®‰è£æ ¸å¿ƒå¥—ä»¶\n",
    "!pip install -q timm>=0.9.0 pyyaml kaggle\n",
    "\n",
    "# é©—è­‰å®‰è£\n",
    "import timm\n",
    "print(f\"âœ… timm version: {timm.__version__}\")\n",
    "\n",
    "# æª¢æŸ¥ DINOv2 æ¨¡å‹\n",
    "dinov2_models = [m for m in timm.list_models() if 'dinov2' in m]\n",
    "print(f\"âœ… DINOv2 models available: {len(dinov2_models)}\")\n",
    "print(f\"   Target model: vit_base_patch14_dinov2.lvd142m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## 3ï¸âƒ£ è¨­ç½® Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaggle_api"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“¤ è«‹ä¸Šå‚³ kaggle.json æ–‡ä»¶...\")\n",
    "print(\"   (å¾ Kaggle â†’ Account â†’ Create New API Token ä¸‹è¼‰)\")\n",
    "print()\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# è¨­ç½® Kaggle API\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# é©—è­‰\n",
    "print(\"\\né©—è­‰ Kaggle API...\")\n",
    "!kaggle competitions list 2>&1 | head -3\n",
    "\n",
    "print(\"\\nâœ… Kaggle API è¨­ç½®æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## 4ï¸âƒ£ Clone GitHub å€‰åº«ä¸¦åˆ‡æ›ç›®éŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# GitHub å€‰åº« URL\n",
    "REPO_URL = \"https://github.com/thc1006/nycu-CSIC30014-LAB3.git\"\n",
    "REPO_NAME = \"nycu-CSIC30014-LAB3\"\n",
    "\n",
    "print(f\"ğŸ“¦ Clone GitHub å€‰åº«: {REPO_URL}\")\n",
    "\n",
    "if os.path.exists(REPO_NAME):\n",
    "    print(f\"   å€‰åº«å·²å­˜åœ¨ï¼Œæ‹‰å–æœ€æ–°ä»£ç¢¼...\")\n",
    "    !cd {REPO_NAME} && git pull\n",
    "else:\n",
    "    print(f\"   æ­£åœ¨ clone...\")\n",
    "    !git clone {REPO_URL}\n",
    "\n",
    "# åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„\n",
    "%cd {REPO_NAME}\n",
    "\n",
    "# é©—è­‰é—œéµæ–‡ä»¶\n",
    "print(\"\\né©—è­‰é—œéµæ–‡ä»¶:\")\n",
    "!ls -lh train_dinov2_breakthrough.py 2>/dev/null && echo \"âœ… è¨“ç·´è…³æœ¬\" || echo \"âŒ è¨“ç·´è…³æœ¬ç¼ºå¤±\"\n",
    "!ls -lh data/fold_0.csv 2>/dev/null && echo \"âœ… Fold æ•¸æ“š\" || echo \"âš ï¸ Fold æ•¸æ“šéœ€è¦ç”Ÿæˆ\"\n",
    "\n",
    "print(\"\\nâœ… å€‰åº«æº–å‚™å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## 5ï¸âƒ£ ä¸‹è¼‰ Kaggle ç«¶è³½æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_data"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ ä¸‹è¼‰ Kaggle ç«¶è³½æ•¸æ“š (ç´„ 3-4 GB)...\")\n",
    "print(\"   é è¨ˆæ™‚é–“: 3-5 åˆ†é˜\\n\")\n",
    "\n",
    "# ä¸‹è¼‰æ•¸æ“š\n",
    "!kaggle competitions download -c cxr-multi-label-classification\n",
    "\n",
    "# è§£å£“åˆ° data ç›®éŒ„\n",
    "print(\"\\nğŸ“¦ è§£å£“æ•¸æ“š...\")\n",
    "!unzip -q cxr-multi-label-classification.zip -d data/\n",
    "!rm cxr-multi-label-classification.zip\n",
    "\n",
    "# é©—è­‰æ•¸æ“š\n",
    "print(\"\\né©—è­‰æ•¸æ“šé›†:\")\n",
    "import os\n",
    "train_count = len([f for f in os.listdir('data/train_images') if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "val_count = len([f for f in os.listdir('data/val_images') if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "test_count = len([f for f in os.listdir('data/test_images') if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "print(f\"âœ… è¨“ç·´å½±åƒ: {train_count} (é æœŸ 2718)\")\n",
    "print(f\"âœ… é©—è­‰å½±åƒ: {val_count} (é æœŸ 679)\")\n",
    "print(f\"âœ… æ¸¬è©¦å½±åƒ: {test_count} (é æœŸ 1182)\")\n",
    "\n",
    "if train_count != 2718 or val_count != 679 or test_count != 1182:\n",
    "    print(\"\\nâš ï¸ è­¦å‘Š: æ•¸æ“šé›†æ•¸é‡ä¸ç¬¦ï¼Œè«‹æª¢æŸ¥ä¸‹è¼‰æ˜¯å¦å®Œæ•´\")\n",
    "else:\n",
    "    print(\"\\nâœ… æ•¸æ“šé›†ä¸‹è¼‰å®Œæˆä¸”æ•¸é‡æ­£ç¢ºï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## 6ï¸âƒ£ æº–å‚™ K-Fold è¨“ç·´æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_folds"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“Š æº–å‚™ K-Fold è¨“ç·´æ•¸æ“š...\\n\")\n",
    "\n",
    "# æª¢æŸ¥ Fold CSV æ˜¯å¦å­˜åœ¨ï¼ˆæ‡‰è©²åœ¨ Git å€‰åº«ä¸­ï¼‰\n",
    "if os.path.exists('data/fold_0.csv'):\n",
    "    print(\"âœ… Fold CSV å·²å­˜åœ¨æ–¼ Git å€‰åº«ä¸­\")\n",
    "    \n",
    "    # ç‚ºæ¯å€‹ fold å‰µå»º train/val åˆ†å‰²\n",
    "    print(\"\\nå‰µå»º Fold è¨“ç·´/é©—è­‰åˆ†å‰²...\")\n",
    "    \n",
    "    # è®€å–åŸå§‹æ•¸æ“š\n",
    "    train_df = pd.read_csv('data/train_data.csv')\n",
    "    val_df = pd.read_csv('data/val_data.csv')\n",
    "    all_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    \n",
    "    for fold in range(5):\n",
    "        # è®€å– fold è³‡è¨Š\n",
    "        fold_df = pd.read_csv(f'data/fold_{fold}.csv')\n",
    "        \n",
    "        # åˆ†å‰² train/val\n",
    "        train_mask = fold_df['fold'] != fold\n",
    "        val_mask = fold_df['fold'] == fold\n",
    "        \n",
    "        fold_train = all_df[train_mask].copy()\n",
    "        fold_val = all_df[val_mask].copy()\n",
    "        \n",
    "        # è¨­ç½®å½±åƒç›®éŒ„ï¼ˆçµ±ä¸€ä½¿ç”¨ç›¸å°è·¯å¾‘ï¼‰\n",
    "        # DINOv2 è¨“ç·´è…³æœ¬æœƒè‡ªå‹•è™•ç†è·¯å¾‘\n",
    "        fold_train['source_dir'] = 'data/train_images'\n",
    "        fold_val['source_dir'] = 'data/val_images'\n",
    "        \n",
    "        # ä¿å­˜\n",
    "        fold_train.to_csv(f'data/fold{fold}_train.csv', index=False)\n",
    "        fold_val.to_csv(f'data/fold{fold}_val.csv', index=False)\n",
    "        \n",
    "        print(f\"  Fold {fold}: Train={len(fold_train):4d}, Val={len(fold_val):3d}\")\n",
    "    \n",
    "    print(\"\\nâœ… Fold æ•¸æ“šæº–å‚™å®Œæˆï¼\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° Fold CSV æ–‡ä»¶\")\n",
    "    print(\"   è«‹ç¢ºä¿ Git å€‰åº«åŒ…å« data/fold_0.csv ~ data/fold_4.csv\")\n",
    "    raise FileNotFoundError(\"Fold CSV files not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## 7ï¸âƒ£ é¸é … A: å¿«é€Ÿé©—è­‰ - è¨“ç·´ Fold 0\n",
    "\n",
    "**å»ºè­°**: å…ˆè·‘ Fold 0 é©—è­‰æ•ˆæœ (1.5-2 å°æ™‚)ï¼Œå¦‚æœ Val F1 â‰¥ 88%ï¼Œå†è·‘å®Œæ•´ 5-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_fold0"
   },
   "outputs": [],
   "source": [
    "# Fold 0 å¿«é€Ÿé©—è­‰\n",
    "FOLD = 0\n",
    "EPOCHS = 35\n",
    "\n",
    "# æ ¹æ“š GPU è‡ªå‹•é¸æ“‡ batch size\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "if \"A100\" in torch.cuda.get_device_name(0):\n",
    "    BATCH_SIZE = 32\n",
    "elif gpu_memory > 14:\n",
    "    BATCH_SIZE = 16\n",
    "else:\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"ğŸš€ é–‹å§‹è¨“ç·´ Fold {FOLD} (å¿«é€Ÿé©—è­‰)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"é è¨ˆæ™‚é–“: {'1.5-2 å°æ™‚ (A100)' if BATCH_SIZE >= 32 else '2-3 å°æ™‚'}\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# è¨“ç·´å‘½ä»¤\n",
    "!python train_dinov2_breakthrough.py \\\n",
    "    --fold {FOLD} \\\n",
    "    --epochs {EPOCHS} \\\n",
    "    --batch_size {BATCH_SIZE} \\\n",
    "    --img_size 518 \\\n",
    "    --lr 3e-5 \\\n",
    "    --output_dir outputs/dinov2_colab\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Fold 0 è¨“ç·´å®Œæˆï¼\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## 8ï¸âƒ£ æª¢æŸ¥ Fold 0 çµæœä¸¦æ±ºç­–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_fold0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“Š åˆ†æ Fold 0 è¨“ç·´çµæœ...\\n\")\n",
    "\n",
    "# æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨\n",
    "model_path = 'outputs/dinov2_colab/fold0/best.pt'\n",
    "if os.path.exists(model_path):\n",
    "    model_size = os.path.getsize(model_path) / 1e6\n",
    "    print(f\"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path} ({model_size:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_path}\")\n",
    "\n",
    "# è®€å–è¨“ç·´æ—¥èªŒ\n",
    "log_file = 'outputs/dinov2_colab/fold0/training.log'\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        log_content = f.read()\n",
    "    \n",
    "    # æå–æœ€ä½³ Val F1\n",
    "    f1_matches = re.findall(r'Val F1: ([\\d.]+)%', log_content)\n",
    "    if f1_matches:\n",
    "        best_f1 = max([float(x) for x in f1_matches])\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ğŸ“ˆ Fold 0 æœ€ä½³é©—è­‰ F1: {best_f1:.2f}%\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # æ±ºç­–å»ºè­°\n",
    "        if best_f1 >= 88:\n",
    "            print(\"âœ… ğŸ‰ çµæœå„ªç§€ï¼å¼·çƒˆå»ºè­°ç¹¼çºŒå®Œæ•´ 5-Fold è¨“ç·´\")\n",
    "            print(\"\\nä¸‹ä¸€æ­¥:\")\n",
    "            print(\"  1. åŸ·è¡Œä¸‹é¢çš„ Cell (å®Œæ•´ 5-Fold è¨“ç·´)\")\n",
    "            print(\"  2. é è¨ˆ 7-10 å°æ™‚å®Œæˆæ‰€æœ‰è¨“ç·´\")\n",
    "            print(\"  3. é æœŸæ¸¬è©¦ F1: 89.5-91.5% (çªç ´ 90% ç›®æ¨™ï¼)\")\n",
    "        elif best_f1 >= 86:\n",
    "            print(\"âš ï¸ çµæœè‰¯å¥½ï¼Œä½†ç•¥ä½æ–¼é æœŸ 88%\")\n",
    "            print(\"\\nå»ºè­°:\")\n",
    "            print(\"  1. å¯ä»¥å˜—è©¦ç¹¼çºŒå®Œæ•´è¨“ç·´\")\n",
    "            print(\"  2. æˆ–èª¿æ•´è¶…åƒæ•¸å¾Œé‡æ–°è¨“ç·´ Fold 0\")\n",
    "        else:\n",
    "            print(\"âŒ çµæœä¸ç†æƒ³ï¼Œéœ€è¦æª¢æŸ¥\")\n",
    "            print(\"\\nå¯èƒ½å•é¡Œ:\")\n",
    "            print(\"  1. æª¢æŸ¥æ•¸æ“šæ˜¯å¦æ­£ç¢ºåŠ è¼‰\")\n",
    "            print(\"  2. æª¢æŸ¥æ˜¯å¦æœ‰è¨“ç·´éŒ¯èª¤\")\n",
    "            print(\"  3. æŸ¥çœ‹å®Œæ•´æ—¥èªŒ: !tail -50 outputs/dinov2_colab/fold0/training.log\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ç„¡æ³•å¾æ—¥èªŒæå– F1 åˆ†æ•¸\")\n",
    "        print(\"è«‹æ‰‹å‹•æª¢æŸ¥æ—¥èªŒ: !tail -100 outputs/dinov2_colab/fold0/training.log\")\n",
    "else:\n",
    "    print(f\"âš ï¸ æ‰¾ä¸åˆ°è¨“ç·´æ—¥èªŒ: {log_file}\")\n",
    "    print(\"è«‹æª¢æŸ¥è¨“ç·´æ˜¯å¦æˆåŠŸå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## 9ï¸âƒ£ é¸é … B: å®Œæ•´è¨“ç·´ - æ‰€æœ‰ 5 Folds\n",
    "\n",
    "**è­¦å‘Š**: éœ€è¦ 7-10 å°æ™‚ (A100) æˆ– 10-15 å°æ™‚ (T4)\n",
    "\n",
    "**å»ºè­°**: åªæœ‰åœ¨ Fold 0 çµæœ â‰¥ 88% æ™‚åŸ·è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_all_folds"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 35\n",
    "\n",
    "# è‡ªå‹•é¸æ“‡ batch size\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "if \"A100\" in torch.cuda.get_device_name(0):\n",
    "    BATCH_SIZE = 32\n",
    "elif gpu_memory > 14:\n",
    "    BATCH_SIZE = 16\n",
    "else:\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš€ é–‹å§‹å®Œæ•´ 5-Fold è¨“ç·´\")\n",
    "print(\"=\"*70)\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"é è¨ˆç¸½æ™‚é–“: {'7-10 å°æ™‚ (A100)' if BATCH_SIZE >= 32 else '10-15 å°æ™‚ (T4)'}\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold in range(5):\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"è¨“ç·´ Fold {fold}/4\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    !python train_dinov2_breakthrough.py \\\n",
    "        --fold {fold} \\\n",
    "        --epochs {EPOCHS} \\\n",
    "        --batch_size {BATCH_SIZE} \\\n",
    "        --img_size 518 \\\n",
    "        --lr 3e-5 \\\n",
    "        --output_dir outputs/dinov2_colab\n",
    "    \n",
    "    fold_time = (time.time() - fold_start) / 60\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    \n",
    "    print(f\"\\nâœ… Fold {fold} å®Œæˆï¼\")\n",
    "    print(f\"   æœ¬ Fold è€—æ™‚: {fold_time:.1f} åˆ†é˜\")\n",
    "    print(f\"   ç´¯è¨ˆè€—æ™‚: {total_time:.1f} åˆ†é˜\")\n",
    "    \n",
    "    if fold < 4:\n",
    "        remaining = fold_time * (4 - fold)\n",
    "        print(f\"   é ä¼°å‰©é¤˜æ™‚é–“: {remaining:.1f} åˆ†é˜ ({remaining/60:.1f} å°æ™‚)\")\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"ğŸ‰ æ‰€æœ‰ 5 Folds è¨“ç·´å®Œæˆï¼\")\n",
    "print(f\"ç¸½è€—æ™‚: {total_time:.1f} åˆ†é˜ ({total_time/60:.1f} å°æ™‚)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## ğŸ”Ÿ ç”Ÿæˆ 5-Fold é›†æˆé æ¸¬ä¸¦æäº¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict_ensemble"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "print(\"ğŸ”® ç”Ÿæˆ 5-Fold é›†æˆé æ¸¬...\\n\")\n",
    "\n",
    "# æ¸¬è©¦é›† Dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, img_size=518):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['new_filename'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, row['new_filename']\n",
    "\n",
    "# æº–å‚™æ¸¬è©¦é›†\n",
    "test_dataset = TestDataset('data/test_data_sample.csv', 'data/test_images')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(f\"âœ… æ¸¬è©¦é›†: {len(test_dataset)} æ¨£æœ¬\")\n",
    "print(f\"âœ… Device: {device}\\n\")\n",
    "\n",
    "# æ”¶é›†æ‰€æœ‰ fold çš„é æ¸¬\n",
    "all_preds = []\n",
    "filenames = None\n",
    "\n",
    "for fold in range(5):\n",
    "    model_path = f'outputs/dinov2_colab/fold{fold}/best.pt'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âš ï¸ Fold {fold} æ¨¡å‹ä¸å­˜åœ¨ï¼Œè·³é\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"ğŸ“Š Fold {fold} é æ¸¬...\")\n",
    "    \n",
    "    # è¼‰å…¥æ¨¡å‹\n",
    "    model = timm.create_model('vit_base_patch14_dinov2.lvd142m', \n",
    "                              pretrained=False, num_classes=4)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # é æ¸¬\n",
    "    fold_probs = []\n",
    "    fold_filenames = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, fnames in tqdm(test_loader, desc=f'Fold {fold}', leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            fold_probs.append(probs.cpu().numpy())\n",
    "            fold_filenames.extend(fnames)\n",
    "    \n",
    "    fold_probs = np.concatenate(fold_probs, axis=0)\n",
    "    all_preds.append(fold_probs)\n",
    "    \n",
    "    if filenames is None:\n",
    "        filenames = fold_filenames\n",
    "    \n",
    "    print(f\"   âœ… å®Œæˆ: {fold_probs.shape}\")\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰ä»»ä½•é æ¸¬\n",
    "if len(all_preds) == 0:\n",
    "    print(\"\\nâŒ éŒ¯èª¤: æ²’æœ‰æ‰¾åˆ°ä»»ä½•è¨“ç·´å¥½çš„æ¨¡å‹\")\n",
    "    print(\"   è«‹ç¢ºä¿è‡³å°‘è¨“ç·´äº†ä¸€å€‹ Fold\")\n",
    "else:\n",
    "    # å¹³å‡æ‰€æœ‰ fold çš„é æ¸¬\n",
    "    print(f\"\\nğŸ“Š é›†æˆ {len(all_preds)} å€‹æ¨¡å‹çš„é æ¸¬...\")\n",
    "    avg_probs = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_probs, axis=1)\n",
    "    \n",
    "    # å‰µå»ºæäº¤æ–‡ä»¶\n",
    "    class_names = ['normal', 'bacteria', 'virus', 'COVID-19']\n",
    "    submission_df = pd.DataFrame({\n",
    "        'new_filename': filenames,\n",
    "        'label': [class_names[p] for p in final_preds]\n",
    "    })\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    submission_path = f'submission_dinov2_{len(all_preds)}fold.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ… é›†æˆé æ¸¬å·²ä¿å­˜: {submission_path}\")\n",
    "    print(f\"\\né æ¸¬åˆ†å¸ƒ:\")\n",
    "    print(submission_df['label'].value_counts())\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"æº–å‚™æäº¤åˆ° Kaggleï¼\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step11"
   },
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ æäº¤åˆ° Kaggle ä¸¦æŸ¥çœ‹çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "submit_kaggle"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# æ‰¾åˆ°æœ€æ–°çš„æäº¤æ–‡ä»¶\n",
    "submission_files = glob.glob('submission_dinov2_*fold.csv')\n",
    "if submission_files:\n",
    "    latest_submission = max(submission_files, key=os.path.getctime)\n",
    "    \n",
    "    print(f\"ğŸ“¤ æäº¤æ–‡ä»¶: {latest_submission}\")\n",
    "    print()\n",
    "    \n",
    "    # æäº¤\n",
    "    !kaggle competitions submit \\\n",
    "        -c cxr-multi-label-classification \\\n",
    "        -f {latest_submission} \\\n",
    "        -m \"DINOv2 Ensemble (Google Colab A100) - Target 90%+\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… æäº¤å®Œæˆï¼\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # æŸ¥çœ‹æœ€è¿‘æäº¤\n",
    "    print(\"\\næœ€è¿‘çš„æäº¤è¨˜éŒ„:\")\n",
    "    !kaggle competitions submissions -c cxr-multi-label-classification | head -10\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ¯ ç­‰å¾… Kaggle è©•åˆ†...\")\n",
    "    print(\"   é€šå¸¸éœ€è¦ 5-10 åˆ†é˜\")\n",
    "    print(\"   å¯ä»¥å‰å¾€ Kaggle ç«¶è³½é é¢æŸ¥çœ‹çµæœ\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"âŒ æ‰¾ä¸åˆ°æäº¤æ–‡ä»¶\")\n",
    "    print(\"   è«‹ç¢ºä¿å·²åŸ·è¡Œé æ¸¬ç”Ÿæˆ Cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step12"
   },
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ (å¯é¸) ä¿å­˜çµæœåˆ° Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"ğŸ’¾ ä¿å­˜çµæœåˆ° Google Drive...\\n\")\n",
    "\n",
    "# æ›è¼‰ Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# å‰µå»ºä¿å­˜ç›®éŒ„\n",
    "save_dir = '/content/drive/MyDrive/CXR_DINOv2_Results'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nä¿å­˜ç›®éŒ„: {save_dir}\\n\")\n",
    "\n",
    "# è¤‡è£½æ¨¡å‹æª¢æŸ¥é»ï¼ˆå¯èƒ½å¾ˆå¤§ï¼Œè¬¹æ…ï¼‰\n",
    "if os.path.exists('outputs/dinov2_colab'):\n",
    "    print(\"ğŸ“¦ è¤‡è£½æ¨¡å‹æª¢æŸ¥é» (å¯èƒ½éœ€è¦å¹¾åˆ†é˜)...\")\n",
    "    shutil.copytree('outputs/dinov2_colab', \n",
    "                   f'{save_dir}/models', \n",
    "                   dirs_exist_ok=True)\n",
    "    print(\"   âœ… æ¨¡å‹å·²ä¿å­˜\")\n",
    "\n",
    "# è¤‡è£½æäº¤æ–‡ä»¶\n",
    "for f in glob.glob('submission_*.csv'):\n",
    "    shutil.copy(f, save_dir)\n",
    "    print(f\"   âœ… {f}\")\n",
    "\n",
    "print(f\"\\nâœ… æ‰€æœ‰çµæœå·²ä¿å­˜åˆ° Google Drive\")\n",
    "print(f\"   ä½ç½®: {save_dir}\")\n",
    "\n",
    "# é¡¯ç¤ºä¿å­˜çš„æ–‡ä»¶\n",
    "!ls -lh {save_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š è¨“ç·´å®Œæˆç¸½çµ\n",
    "\n",
    "### âœ… å®Œæˆæª¢æŸ¥æ¸…å–®\n",
    "\n",
    "- [ ] ç’°å¢ƒæª¢æŸ¥é€šéï¼ˆGPU: A100ï¼‰\n",
    "- [ ] æ‰€æœ‰ä¾è³´å®‰è£æˆåŠŸ\n",
    "- [ ] Kaggle API è¨­ç½®å®Œæˆ\n",
    "- [ ] GitHub å€‰åº« clone æˆåŠŸ\n",
    "- [ ] æ•¸æ“šé›†ä¸‹è¼‰å®Œæˆï¼ˆ3.4 GBï¼‰\n",
    "- [ ] Fold æ•¸æ“šæº–å‚™å®Œæˆ\n",
    "- [ ] Fold 0 é©—è­‰å®Œæˆï¼ˆVal F1 â‰¥ 88%ï¼‰\n",
    "- [ ] 5-Fold å®Œæ•´è¨“ç·´å®Œæˆ\n",
    "- [ ] é›†æˆé æ¸¬ç”Ÿæˆ\n",
    "- [ ] æäº¤åˆ° Kaggle\n",
    "- [ ] çµæœä¿å­˜åˆ° Google Drive\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ é æœŸçµæœ\n",
    "\n",
    "- **ç•¶å‰æœ€ä½³**: 87.574%\n",
    "- **DINOv2 ç›®æ¨™**: 89.5-91.5%\n",
    "- **çªç ´ç›®æ¨™**: 90%+\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ ä¸‹ä¸€æ­¥\n",
    "\n",
    "#### å¦‚æœé”åˆ° 90%+ âœ…\n",
    "1. å˜—è©¦ DINOv2-Large æ¨¡å‹ï¼ˆæ›´å¤§ï¼‰\n",
    "2. èˆ‡ç¾æœ‰æœ€ä½³æ¨¡å‹é›†æˆ\n",
    "3. æ¢ç´¢ Test-Time Augmentation\n",
    "\n",
    "#### å¦‚æœæœªé”æ¨™ (< 89%) âš ï¸\n",
    "1. æª¢æŸ¥è¨“ç·´æ—¥èªŒï¼Œåˆ†æå•é¡Œ\n",
    "2. èª¿æ•´è¶…åƒæ•¸ï¼ˆlearning rate, batch sizeï¼‰\n",
    "3. å˜—è©¦å…¶ä»–æ–¹æ¡ˆï¼ˆè¦‹ BREAKTHROUGH_STRATEGY_ANALYSIS.mdï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "**é …ç›®å€‰åº«**: https://github.com/thc1006/nycu-CSIC30014-LAB3\n",
    "\n",
    "**å®Œæ•´æ–‡æª”**: è¦‹ CLAUDE.md å’Œ MACHINE_HANDOFF_GUIDE.md\n",
    "\n",
    "**ç¥æ‚¨çªç ´ 90%ï¼** ğŸš€\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
