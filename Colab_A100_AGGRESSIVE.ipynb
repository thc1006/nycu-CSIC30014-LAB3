{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ A100 AGGRESSIVE - DINOv2 å®Œæ•´ 5-Fold è¨“ç·´\n",
    "\n",
    "**GPUè¦æ±‚**: A100 (40GB)\n",
    "**Batch Size**: 24 (æ¿€é€²)\n",
    "**é è¨ˆæ™‚é–“**: 2-3 å°æ™‚ (å®Œæ•´ 5-Fold)\n",
    "**ç›®æ¨™åˆ†æ•¸**: 90%+\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ è¨­ç½®æ­¥é©Ÿ\n",
    "1. Runtime â†’ Change runtime type â†’ **A100 GPU**\n",
    "2. æº–å‚™ `kaggle.json` (Kaggle â†’ Account â†’ Create API Token)\n",
    "3. é †åºåŸ·è¡Œæ‰€æœ‰ Cell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ç’°å¢ƒæª¢æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” GPU æª¢æŸ¥\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"âŒ No GPU! è«‹å•Ÿç”¨ A100: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "\n",
    "print(f\"âœ… GPU: {gpu_name}\")\n",
    "print(f\"âœ… VRAM: {gpu_memory:.1f} GB\")\n",
    "\n",
    "if \"A100\" not in gpu_name:\n",
    "    print(f\"\\nâš ï¸ è­¦å‘Š: æª¢æ¸¬åˆ° {gpu_name}ï¼Œä¸æ˜¯ A100ï¼\")\n",
    "    print(\"   æœ¬ Notebook é‡å° A100 å„ªåŒ–ï¼Œå…¶ä»– GPU è«‹ä½¿ç”¨å°æ‡‰ç‰ˆæœ¬\")\n",
    "    raise RuntimeError(\"Please use A100 GPU for this notebook\")\n",
    "\n",
    "# A100 æ¿€é€²é…ç½®\n",
    "BATCH_SIZE = 24\n",
    "EXPECTED_TIME_PER_FOLD = \"25-30 åˆ†é˜\"\n",
    "TOTAL_TIME = \"2-2.5 å°æ™‚\"\n",
    "\n",
    "print(f\"\\nğŸš€ A100 æ¿€é€²é…ç½®:\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   é è¨ˆæ™‚é–“/fold: {EXPECTED_TIME_PER_FOLD}\")\n",
    "print(f\"   é è¨ˆç¸½æ™‚é–“: {TOTAL_TIME}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ å®‰è£ä¾è³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q timm>=1.0.0 pyyaml kaggle scikit-learn tqdm\n",
    "\n",
    "import timm\n",
    "print(f\"âœ… timm: {timm.__version__}\")\n",
    "\n",
    "dinov2_models = [m for m in timm.list_models() if 'dinov2' in m and 'base' in m]\n",
    "print(f\"âœ… DINOv2 models: {dinov2_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import json\n",
    "\n",
    "print(\"ğŸ”‘ å¾ Colab Secrets è®€å– Kaggle API...\")\n",
    "\n",
    "# å¾ Colab Secrets è®€å– API key\n",
    "try:\n",
    "    kaggle_key = userdata.get('KAGGLE_KEY')\n",
    "    print(\"âœ… æˆåŠŸè®€å– KAGGLE_KEY\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ ç„¡æ³•è®€å– KAGGLE_KEY\")\n",
    "    print(\"è«‹åœ¨å·¦å´é‚Šæ¬„ ğŸ”‘ Secrets ä¸­æ·»åŠ :\")\n",
    "    print(\"   åç¨±: KAGGLE_KEY\")\n",
    "    print(\"   å€¼: ä½ çš„ Kaggle API key\")\n",
    "    raise e\n",
    "\n",
    "# å‰µå»º kaggle.json\n",
    "kaggle_config = {\n",
    "    \"username\": \"thc1006\",\n",
    "    \"key\": kaggle_key\n",
    "}\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump(kaggle_config, f)\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"âœ… Kaggle API é…ç½®å®Œæˆ (username: thc1006)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Clone GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/thc1006/nycu-CSIC30014-LAB3.git\"\n",
    "REPO_NAME = \"nycu-CSIC30014-LAB3\"\n",
    "\n",
    "if os.path.exists(REPO_NAME):\n",
    "    !cd {REPO_NAME} && git pull\n",
    "else:\n",
    "    !git clone {REPO_URL}\n",
    "\n",
    "%cd {REPO_NAME}\n",
    "print(f\"âœ… ç•¶å‰ç›®éŒ„: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ ä¸‹è¼‰æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¥ ä¸‹è¼‰ Kaggle æ•¸æ“š (~700MB)...\")\n",
    "!kaggle competitions download -c cxr-multi-label-classification\n",
    "!unzip -q cxr-multi-label-classification.zip -d data/\n",
    "!rm cxr-multi-label-classification.zip\n",
    "\n",
    "# é©—è­‰æ•¸æ“š\n",
    "import glob\n",
    "train_images = glob.glob('data/train_images/*.jpg') + glob.glob('data/train_images/*.jpeg') + glob.glob('data/train_images/*.png')\n",
    "test_images = glob.glob('data/test_images/*.jpg') + glob.glob('data/test_images/*.jpeg') + glob.glob('data/test_images/*.png')\n",
    "\n",
    "print(f\"âœ… è¨“ç·´å½±åƒ: {len(train_images)}\")\n",
    "print(f\"âœ… æ¸¬è©¦å½±åƒ: {len(test_images)}\")\n",
    "print(f\"âœ… CSV æª”æ¡ˆå·²å¾ GitHub åŒæ­¥\")\n",
    "\n",
    "# Kaggle ç«¶è³½åªæœ‰ train_images å’Œ test_images\n",
    "# train/val split ç”± CSV æ§åˆ¶\n",
    "assert len(test_images) == 1182, f\"æ¸¬è©¦é›†ä¸å®Œæ•´: {len(test_images)} != 1182\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ æº–å‚™ K-Fold æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Kaggle ç«¶è³½æ•¸æ“šçµæ§‹: åªæœ‰ train_images/ å’Œ test_images/\n",
    "# fold CSV å·²å¾ GitHub åŒæ­¥ï¼Œç›´æ¥ä½¿ç”¨\n",
    "print(\"ğŸ“‹ é©—è­‰ Fold CSV...\")\n",
    "\n",
    "for fold in range(5):\n",
    "    train_csv = f'data/fold{fold}_train.csv'\n",
    "    val_csv = f'data/fold{fold}_val.csv'\n",
    "    \n",
    "    if not os.path.exists(train_csv) or not os.path.exists(val_csv):\n",
    "        print(f\"âŒ Fold {fold} CSV ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ\")\n",
    "        raise FileNotFoundError(f\"Missing fold CSV for fold {fold}\")\n",
    "    \n",
    "    train_df = pd.read_csv(train_csv)\n",
    "    val_df = pd.read_csv(val_csv)\n",
    "    \n",
    "    # ä¿®æ­£ source_dir: Kaggle æ‰€æœ‰è¨“ç·´å½±åƒéƒ½åœ¨ train_images/\n",
    "    train_df['source_dir'] = 'data/train_images'\n",
    "    val_df['source_dir'] = 'data/train_images'  # âœ… Kaggle çµæ§‹\n",
    "    \n",
    "    # ä¿å­˜ä¿®æ­£å¾Œçš„ CSV\n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    val_df.to_csv(val_csv, index=False)\n",
    "    \n",
    "    print(f\"âœ… Fold {fold}: Train={len(train_df)}, Val={len(val_df)}\")\n",
    "\n",
    "print(\"\\nâœ… Fold æ•¸æ“šæº–å‚™å®Œæˆ (å·²é©é… Kaggle çµæ§‹)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ å®Œæ•´ 5-Fold è¨“ç·´ (A100 æ¿€é€²æ¨¡å¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 24  # A100 æ¿€é€²\n",
    "IMG_SIZE = 518\n",
    "LR = 3e-5\n",
    "OUTPUT_DIR = \"outputs/dinov2_a100_aggressive\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš€ A100 æ¿€é€²è¨“ç·´é–‹å§‹\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"é è¨ˆç¸½æ™‚é–“: 2-2.5 å°æ™‚\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold in range(5):\n",
    "    fold_start = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ“Š Fold {fold}/4 è¨“ç·´ä¸­...\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    !python3 train_dinov2_breakthrough.py \\\n",
    "        --fold {fold} \\\n",
    "        --epochs {EPOCHS} \\\n",
    "        --batch_size {BATCH_SIZE} \\\n",
    "        --img_size {IMG_SIZE} \\\n",
    "        --lr {LR} \\\n",
    "        --output_dir {OUTPUT_DIR}\n",
    "    \n",
    "    fold_time = (time.time() - fold_start) / 60\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    \n",
    "    print(f\"\\nâœ… Fold {fold} å®Œæˆ: {fold_time:.1f} åˆ†é˜\")\n",
    "    print(f\"   ç´¯è¨ˆ: {total_time:.1f} åˆ†é˜ ({total_time/60:.1f} å°æ™‚)\")\n",
    "    \n",
    "    if fold < 4:\n",
    "        remaining = fold_time * (4 - fold)\n",
    "        print(f\"   é ä¼°å‰©é¤˜: {remaining:.1f} åˆ†é˜ ({remaining/60:.1f} å°æ™‚)\")\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ğŸ‰ å…¨éƒ¨è¨“ç·´å®Œæˆï¼\")\n",
    "print(f\"ç¸½è€—æ™‚: {total_time:.1f} åˆ†é˜ ({total_time/60:.2f} å°æ™‚)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ ç”Ÿæˆ 5-Fold é›†æˆé æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, img_size=518):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((img_size, img_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['new_filename'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        return self.transform(img), row['new_filename']\n",
    "\n",
    "# æº–å‚™æ¸¬è©¦é›†\n",
    "test_dataset = TestDataset('data/test_data_sample.csv', 'data/test_images', img_size=518)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(f\"âœ… æ¸¬è©¦é›†: {len(test_dataset)} æ¨£æœ¬\\n\")\n",
    "\n",
    "# æ”¶é›†æ‰€æœ‰ fold é æ¸¬\n",
    "all_preds = []\n",
    "filenames = None\n",
    "\n",
    "for fold in range(5):\n",
    "    model_path = f'{OUTPUT_DIR}/fold{fold}/best.pt'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âš ï¸ Fold {fold} æ¨¡å‹ä¸å­˜åœ¨ï¼Œè·³é\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"ğŸ“Š Fold {fold} é æ¸¬ä¸­...\")\n",
    "    \n",
    "    # è¼‰å…¥æ¨¡å‹ (ä¿®æ­£: ä½¿ç”¨æ­£ç¢ºçš„æ¨¡å‹åç¨±å’Œè¼‰å…¥æ–¹å¼)\n",
    "    model = timm.create_model('vit_base_patch14_dinov2', pretrained=False, num_classes=4)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  # âœ… ä¿®æ­£\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    fold_probs = []\n",
    "    fold_filenames = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, fnames in tqdm(test_loader, desc=f'Fold {fold}', leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            fold_probs.append(probs.cpu().numpy())\n",
    "            fold_filenames.extend(fnames)\n",
    "    \n",
    "    fold_probs = np.concatenate(fold_probs, axis=0)\n",
    "    all_preds.append(fold_probs)\n",
    "    \n",
    "    if filenames is None:\n",
    "        filenames = fold_filenames\n",
    "    \n",
    "    print(f\"   âœ… å®Œæˆ\\n\")\n",
    "\n",
    "# é›†æˆ\n",
    "print(f\"ğŸ”® é›†æˆ {len(all_preds)} å€‹æ¨¡å‹...\")\n",
    "avg_probs = np.mean(all_preds, axis=0)\n",
    "final_preds = np.argmax(avg_probs, axis=1)\n",
    "\n",
    "# å‰µå»ºæäº¤\n",
    "class_names = ['normal', 'bacteria', 'virus', 'COVID-19']\n",
    "submission_df = pd.DataFrame({\n",
    "    'new_filename': filenames,\n",
    "    'label': [class_names[p] for p in final_preds]\n",
    "})\n",
    "\n",
    "submission_path = f'submission_a100_aggressive_{len(all_preds)}fold.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {submission_path}\")\n",
    "print(f\"\\né æ¸¬åˆ†å¸ƒ:\")\n",
    "print(submission_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ æäº¤åˆ° Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "submission_files = glob.glob('submission_a100_*.csv')\n",
    "if submission_files:\n",
    "    latest = max(submission_files, key=os.path.getctime)\n",
    "    \n",
    "    print(f\"ğŸ“¤ æäº¤: {latest}\\n\")\n",
    "    \n",
    "    !kaggle competitions submit \\\n",
    "        -c cxr-multi-label-classification \\\n",
    "        -f {latest} \\\n",
    "        -m \"DINOv2 5-Fold A100 Aggressive (BS=24) - Target 90%+\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… æäº¤å®Œæˆï¼\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\næœ€è¿‘æäº¤:\")\n",
    "    !kaggle competitions submissions -c cxr-multi-label-classification | head -10\n",
    "else:\n",
    "    print(\"âŒ æ‰¾ä¸åˆ°æäº¤æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… å®Œæˆ\n",
    "\n",
    "**é æœŸçµæœ**: 89.5-91.5% Macro-F1\n",
    "\n",
    "**ç¸½æ™‚é–“**: ~2-2.5 å°æ™‚ (A100)\n",
    "\n",
    "**GitHub**: https://github.com/thc1006/nycu-CSIC30014-LAB3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}